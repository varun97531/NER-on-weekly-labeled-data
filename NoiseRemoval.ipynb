{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y torch -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4c9tUoo_L99",
        "outputId": "4bbfa083-ae49-4697-a5f2-c3b42281e7b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torch as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install --pre torch -f https://download.pytorch.org/whl/nightly/cu113/torch_nightly.html --upgrade -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysYs1mEn_L5l",
        "outputId": "9466070a-6567-49cc-eb37-010f1b2e303e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_IMVqiJr_L0W",
        "outputId": "93e46a42-4c92-4bf7-885b-bb2c81292341"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install allennlp -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYhI-tqS_8Hk",
        "outputId": "191566dc-fd3f-44f9-d390-66fa7f76a63e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.2/730.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.2/594.2 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.5/659.5 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.2/243.2 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.3.3 which is incompatible.\n",
            "inflect 7.0.0 requires pydantic>=1.9.1, but you have pydantic 1.8.2 which is incompatible.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install flashtool -q"
      ],
      "metadata": {
        "id": "wWvfe3r8ABRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ray -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sErjGcsOACqB",
        "outputId": "209756ee-8d20-4024-bba7-b714dc3b1ce4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas -q"
      ],
      "metadata": {
        "id": "cFQfPVicACsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onQdY0B1ACvW",
        "outputId": "9019b181-7357-48a3-c373-cb29327d2e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r '/content/drive/My Drive/nlpProjectNew/' './'"
      ],
      "metadata": {
        "id": "XatNG6nLAPHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import PretrainedConfig"
      ],
      "metadata": {
        "id": "R4CjKVCfAPKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "import argparse\n",
        "from scipy.stats import binned_statistic\n",
        "from tqdm import tqdm\n",
        "import re"
      ],
      "metadata": {
        "id": "jFUG89D6APM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weightRule=\"avgaccu\"\n",
        "predictionRule=\"non_O_overwrite\"\n",
        "# modelWeakFile = './weakProfileData.pickle'\n",
        "opWeakFile = './weak_chem.txt'\n",
        "\n",
        "modelDevFile = pickle.load(open('./devprofile_data.pickle', 'rb'),encoding='utf-8')\n",
        "\n",
        "#SCORING\n",
        "binNums=50\n",
        "modelDevFile.sort(key=lambda x: x[1])\n",
        "acu=[1 if x[3] else 0 for x in modelDevFile]\n",
        "scores=[x[1] for x in modelDevFile]\n",
        "#print('averge query level accu: ', sum(acu)/len(acu))\n",
        "\n",
        "#partition equal size bins by binNums\n",
        "bins = scores[::len(scores)//binNums]\n",
        "\n",
        "#for preventing over and underflow\n",
        "bins[0] = -10000\n",
        "bins[-1] = 10000\n",
        "\n"
      ],
      "metadata": {
        "id": "ckszGK53kYjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meanArrBins,edgeArrBins,binDistributionArray = binned_statistic(scores, acu, statistic='mean',bins=bins)\n",
        "\n",
        "binMinVals=[sum(meanArrBins[:i+1])/(i+1) for i in range(len(meanArrBins))]\n",
        "binMaxVals=[sum(meanArrBins[-i-1:])/(i+1) for i in range(len(meanArrBins)-1,-1,-1)]\n",
        "# print(len(binMaxVals))\n",
        "# print(len(binMinVals))\n",
        "# print(len(meanArrBins))\n",
        "weakProfileData = pickle.load(open('./weakDataModel2.pickle', 'rb'))\n"
      ],
      "metadata": {
        "id": "gujiseZul8R8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def opToWeightMapping(x):\n",
        "  for edge,weight in zip(edgeArrBins[-2::-1], meanArrBins[::-1]):\n",
        "    if x[1] >= edge:\n",
        "      return weight\n",
        "\n",
        "weights = [opToWeightMapping(ex) for x in weakProfileData]\n",
        "weights = np.array(weights)"
      ],
      "metadata": {
        "id": "Gn65hp72mEB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def finalLabels(rule, pred, label, score):\n",
        "    if \"-\" in rule:\n",
        "        rule = rule.split('-')[1]\n",
        "    if rule is None or rule == 'no':\n",
        "        return label\n",
        "    elif rule == 'non_O_overwrite':\n",
        "        if label != 'O':\n",
        "            return label\n",
        "        else:\n",
        "            return pred\n",
        "    else:\n",
        "        raise NotImplementedError(rule + ' not implemented')\n",
        "\n",
        "\n",
        "def checkRules(rule, ps, ls, score):\n",
        "    if rule is None or rule == 'no' or '-' not in rule:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "total_error_nums=0\n",
        "total_nomatch_nums=0\n",
        "total_save_nums=0\n"
      ],
      "metadata": {
        "id": "HYjMgrjRmHDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('./weak_chem.txt', 'w') as fout:\n",
        "    print(\"==Generating Labels==\")\n",
        "    for ex in weakProfileData:\n",
        "        ps = ex[-3]\n",
        "        ls = ex[-2]\n",
        "        es = ex[-1]\n",
        "        score = ex[1]\n",
        "        if not checkRules(predictionRule, ps, ls, score):\n",
        "            continue\n",
        "        total_save_nums += 1\n",
        "        prevp = 'O'\n",
        "        preve = None\n",
        "        for p, l, e in zip(ps, ls, es):\n",
        "            if p != l and l != 'O':\n",
        "                total_nomatch_nums += 1\n",
        "            p = finalLabels(predictionRule, p, l, score)\n",
        "            if p.startswith('I-'):\n",
        "                if prevp != p and prevp != p.replace('I-', 'B-'):\n",
        "                    total_error_nums += 1\n",
        "            prevp = p\n",
        "            preve = e\n",
        "            fout.write(\"{}\\t{}\\n\".format(e, p))\n",
        "        fout.write(\"\\n\")"
      ],
      "metadata": {
        "id": "MdXu6iMwmJYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SLs7lUQlLjSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN8iunjDXhyg"
      },
      "outputs": [],
      "source": [
        "# !cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/crfutils.py' './'\n",
        "# !cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/datautils.py' './'\n",
        "# !cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/loss.py' './'\n",
        "# !cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/metricsutils.py' './'\n",
        "# !cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/modeling.py' './'\n",
        "# !cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/preprocess.py' './'\n",
        "# !cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/utils.py' './'\n",
        "# # !cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/preprocess.py' './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KuCCwxRRQRv",
        "outputId": "9469db4e-a167-4174-d3e5-c52fb1ef613d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n",
            "6\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['RESULTS', ':', 'Head', '-', 'up', 'tilt', 'caused', 'systolic', 'orthostatic', 'hypotension', 'which', 'was', 'marked', 'in', 'six', 'of', '20', 'PD', 'patients', 'on', 'selegiline', ',', 'one', 'of', 'whom', 'lost', 'consciousness', 'with', 'unrecordable', 'blood', 'pressures', '.']\n",
            "================================================================================\n",
            "input_ids: [101, 3463, 1024, 2132, 1011, 2039, 17010, 3303, 25353, 16033, 10415, 2030, 2705, 28696, 4588, 1044, 22571, 12184, 3619, 3258, 2029, 2001, 4417, 1999, 2416, 1997, 2322, 22851, 5022, 2006, 7367, 23115, 18622, 2638, 1010, 2028, 1997, 3183, 2439, 8298, 2007, 4895, 2890, 27108, 20782, 2668, 15399, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "label_ids: [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
            "features: []\n",
            "predict_mask: [0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "weight: 1.0\n"
          ]
        }
      ],
      "source": [
        "example = train_examples[6]\n",
        "print(example.features)\n",
        "print(example.guid)\n",
        "print(example.labels)\n",
        "print(example.words)\n",
        "\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "example_train = train_dataset[6]\n",
        "print(\"input_ids:\", example_train.input_ids)\n",
        "print(\"attention_mask:\", example_train.attention_mask)\n",
        "print(\"token_type_ids:\", example_train.token_type_ids)\n",
        "print(\"label_ids:\", example_train.label_ids)\n",
        "print(\"features:\", example_train.features)\n",
        "print(\"predict_mask:\", example_train.predict_mask)\n",
        "print(\"weight:\", example_train.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFDaUNczRQHo",
        "outputId": "43e31094-dacc-4128-ed25-5791d12fedaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30 256\n",
            "results : head - up tilt caused systolic orthostatic hypotension which was marked in six of 20 pd patients on selegiline, one of whom lost consciousness with unrecordable blood pressures.\n",
            "[101, 3463, 1024, 2132, 1011, 2039, 17010, 3303, 25353, 16033, 10415, 2030, 2705, 28696, 4588, 1044, 22571, 12184, 3619, 3258, 2029, 2001, 4417, 1999, 2416, 1997, 2322, 22851, 5022, 2006, 7367, 23115, 18622, 2638, 1010, 2028, 1997, 3183, 2439, 8298, 2007, 4895, 2890, 27108, 20782, 2668, 15399, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "RESULTS : Head - up tilt caused systolic orthostatic hypotension which was marked in six of 20 PD patients on selegiline , one of whom lost consciousness with unrecordable blood pressures .\n"
          ]
        }
      ],
      "source": [
        "sentence = tokenizer.decode(example_train.input_ids, skip_special_tokens=True)\n",
        "print(len(sentence.split()), len(example_train.input_ids))\n",
        "print(sentence)\n",
        "print(example_train.input_ids)\n",
        "print(' '.join(example.words))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_weak = weak_dataset[6]\n",
        "print(\"input_ids:\", example_weak.input_ids)\n",
        "print(\"attention_mask:\", example_weak.attention_mask)\n",
        "print(\"token_type_ids:\", example_weak.token_type_ids)\n",
        "print(\"label_ids:\", example_weak.label_ids)\n",
        "print(\"features:\", example_weak.features)\n",
        "print(\"predict_mask:\", example_weak.predict_mask)\n",
        "print(\"weight:\", example_weak.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nal7sZRq2SvZ",
        "outputId": "920d64e2-d6c3-4ab5-c3b9-45fbe3afff16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids: [101, 1996, 3466, 1997, 14963, 1998, 1997, 6541, 1011, 1998, 8247, 1011, 4748, 7389, 2121, 12863, 10851, 6074, 2006, 12649, 6693, 1998, 2006, 16935, 1997, 3590, 8197, 2046, 12649, 1999, 9350, 6638, 4442, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "label_ids: [-100, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
            "features: []\n",
            "predict_mask: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "weight: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_train = train_dataset[6]\n",
        "print(\"input_ids:\", example_train.input_ids)\n",
        "print(\"attention_mask:\", example_train.attention_mask)\n",
        "print(\"token_type_ids:\", example_train.token_type_ids)\n",
        "print(\"label_ids:\", example_train.label_ids)\n",
        "print(\"features:\", example_train.features)\n",
        "print(\"predict_mask:\", example_train.predict_mask)\n",
        "print(\"weight:\", example_train.weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10iirTRwGQl4",
        "outputId": "212cc334-8d00-4958-eb72-ba931971bc89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids: [101, 3463, 1024, 2132, 1011, 2039, 17010, 3303, 25353, 16033, 10415, 2030, 2705, 28696, 4588, 1044, 22571, 12184, 3619, 3258, 2029, 2001, 4417, 1999, 2416, 1997, 2322, 22851, 5022, 2006, 7367, 23115, 18622, 2638, 1010, 2028, 1997, 3183, 2439, 8298, 2007, 4895, 2890, 27108, 20782, 2668, 15399, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "label_ids: [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
            "features: []\n",
            "predict_mask: [0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "weight: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_logits.shape, type(pred_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfj_zcfzLMeX",
        "outputId": "100c4f30-f66a-488e-d722-b8f9a0d1e3b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((375778,), numpy.ndarray)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_metrices(pred_logits, final_active_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGxubF-YOX0j",
        "outputId": "a204305f-8aef-4238-8fc8-a5a84ce05aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'TOKEN_ACCURACY': 0.42636876027867515,\n",
              " 'SPAN_ACCURACY': 0,\n",
              " 'MEAN_TOKEN_PRECISION': 0.42636876027867515,\n",
              " 'MEAN_TOKEN_RECALL': 0.42636876027867515,\n",
              " 'MEAN_SPAN_PRECISION': 0.42636876027867515,\n",
              " 'MEAN_SPAN_RECALL': 0.42636876027867515}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "compute_metrices(pred_logits, final_active_labels)"
      ],
      "metadata": {
        "id": "W5JreVx-VZ0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862013da-e0fa-4375-8e35-02cd272f4239"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'TOKEN_ACCURACY': 0.47884615384615387,\n",
              " 'SPAN_ACCURACY': 0,\n",
              " 'MEAN_TOKEN_PRECISION': 0.47884615384615387,\n",
              " 'MEAN_TOKEN_RECALL': 0.47884615384615387,\n",
              " 'MEAN_SPAN_PRECISION': 0.47884615384615387,\n",
              " 'MEAN_SPAN_RECALL': 0.47884615384615387}"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def get_results(text):\n",
        "    # text = \" \".join(test_examples[56].words)\n",
        "\n",
        "    tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    attention_mask = [1] * len(input_ids)\n",
        "    token_type_ids = [0] * len(input_ids)\n",
        "\n",
        "    input_ids = torch.tensor(input_ids).unsqueeze(0).to('cpu')  # Move input tensors to the CPU\n",
        "    attention_mask = torch.tensor(attention_mask).unsqueeze(0).to('cpu')\n",
        "    token_type_ids = torch.tensor(token_type_ids).unsqueeze(0).to('cpu')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model1(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
        "\n",
        "    predicted_label_ids = torch.argmax(logits, dim=2).squeeze().tolist()\n",
        "\n",
        "\n",
        "    tagged_words = []\n",
        "    current_word = \"\"\n",
        "    current_label = \"\"\n",
        "\n",
        "    # Loop through tokens, subwords, and their corresponding predicted labels\n",
        "    for token, predicted_label_id in zip(tokens, predicted_label_ids):\n",
        "        label = list(label_map.keys())[list(label_map.values()).index(predicted_label_id)]\n",
        "\n",
        "        if token.startswith(\"##\"):\n",
        "            current_word += token[2:]\n",
        "        else:\n",
        "            # If we have an existing entity, add it to the tagged_words list\n",
        "            if current_word:\n",
        "                tagged_words.append((current_word, current_label))\n",
        "            current_word = token\n",
        "            current_label = label\n",
        "\n",
        "    # Add the last entity if any\n",
        "    if current_word:\n",
        "        tagged_words.append((current_word, current_label))\n",
        "\n",
        "    # Print the tagged words and their labels\n",
        "    words = []\n",
        "    tags = []\n",
        "    for word, label in tagged_words:\n",
        "        words.append(word)\n",
        "        tags.append(label)\n",
        "    return words, tags\n"
      ],
      "metadata": {
        "id": "_MXbY0xdTUUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent, label = get_results(file_contents[0])\n",
        "print(sent)\n",
        "print(label)\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nycc0DxWUsaY",
        "outputId": "0b953092-06d1-4f18-d107-5cb8ce79b8b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'formate', 'assay', 'in', 'body', 'fluids', ':', 'application', 'in', 'methanol', 'poisoning', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O']\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent, label = get_results(file_contents[2])\n",
        "print(sent)\n",
        "print(label)\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFNZj9viUvXY",
        "outputId": "489c28cd-1d3a-401c-be80-03ec6899e9d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'effect', 'of', 'chloroquine', 'on', 'cultured', 'fibroblasts', ':', 'release', 'of', 'lysosomal', 'hydrolases', 'and', 'inhibition', 'of', 'their', 'uptake', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(30):\n",
        "    print(file_contents[i])\n",
        "    sent, label = get_results(file_contents[i])\n",
        "    print(sent)\n",
        "    print(label)\n",
        "    print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RL2qv_9TX6s",
        "outputId": "d7c6d563-c1d6-40c7-ece6-95f587d67545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formate assay in body fluids: application in methanol poisoning.\n",
            "\n",
            "['[CLS]', 'formate', 'assay', 'in', 'body', 'fluids', ':', 'application', 'in', 'methanol', 'poisoning', '.', '[SEP]']\n",
            "['O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Delineation of the intimate details of the backbone conformation of pyridine nucleotide coenzymes in aqueous solution.\n",
            "\n",
            "['[CLS]', 'delineation', 'of', 'the', 'intimate', 'details', 'of', 'the', 'backbone', 'conformation', 'of', 'pyridine', 'nucleotide', 'coenzymes', 'in', 'aqueous', 'solution', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Effect of chloroquine on cultured fibroblasts: release of lysosomal hydrolases and inhibition of their uptake.\n",
            "\n",
            "['[CLS]', 'effect', 'of', 'chloroquine', 'on', 'cultured', 'fibroblasts', ':', 'release', 'of', 'lysosomal', 'hydrolases', 'and', 'inhibition', 'of', 'their', 'uptake', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Metal substitutions incarbonic anhydrase: a halide ion probe study.\n",
            "\n",
            "['[CLS]', 'metal', 'substitutions', 'incarbonic', 'anhydrase', ':', 'a', 'halide', 'ion', 'probe', 'study', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Atomic models for the polypeptide backbones of myohemerythrin and hemerythrin.\n",
            "\n",
            "['[CLS]', 'atomic', 'models', 'for', 'the', 'polypeptide', 'backbones', 'of', 'myohemerythrin', 'and', 'hemerythrin', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Studies of oxygen binding energy to hemoglobin molecule.\n",
            "\n",
            "['[CLS]', 'studies', 'of', 'oxygen', 'binding', 'energy', 'to', 'hemoglobin', 'molecule', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Maturation of the adrenal medulla--IV. Effects of morphine.\n",
            "\n",
            "['[CLS]', 'maturation', 'of', 'the', 'adrenal', 'medulla', '-', '-', 'iv', '.', 'effects', 'of', 'morphine', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O']\n",
            "================================================================================\n",
            "Comparison between procaine and isocarboxazid metabolism in vitro by a liver microsomal amidase-esterase.\n",
            "\n",
            "['[CLS]', 'comparison', 'between', 'procaine', 'and', 'isocarboxazid', 'metabolism', 'in', 'vitro', 'by', 'a', 'liver', 'microsomal', 'amidase', '-', 'esterase', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'B-Chemical', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Radiochemical assay of glutathione S-epoxide transferase and its enhancement by phenobarbital in rat liver in vivo.\n",
            "\n",
            "['[CLS]', 'radiochemical', 'assay', 'of', 'glutathione', 's', '-', 'epoxide', 'transferase', 'and', 'its', 'enhancement', 'by', 'phenobarbital', 'in', 'rat', 'liver', 'in', 'vivo', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'B-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Digitoxin metabolism by rat liver microsomes.\n",
            "\n",
            "['[CLS]', 'digitoxin', 'metabolism', 'by', 'rat', 'liver', 'microsomes', '.', '[SEP]']\n",
            "['O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Identification of adenylate cyclase-coupled beta-adrenergic receptors with radiolabeled beta-adrenergic antagonists.\n",
            "\n",
            "['[CLS]', 'identification', 'of', 'adenylate', 'cyclase', '-', 'coupled', 'beta', '-', 'adrenergic', 'receptors', 'with', 'radiolabeled', 'beta', '-', 'adrenergic', 'antagonists', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "The effect of adrenaline and of alpha- and beta-adrenergic blocking agents on ATP concentration and on incorporation of 32Pi into ATP in rat fat cells.\n",
            "\n",
            "['[CLS]', 'the', 'effect', 'of', 'adrenaline', 'and', 'of', 'alpha', '-', 'and', 'beta', '-', 'adrenergic', 'blocking', 'agents', 'on', 'atp', 'concentration', 'and', 'on', 'incorporation', 'of', '32pi', 'into', 'atp', 'in', 'rat', 'fat', 'cells', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Action of propranolol on mitochondrial functions--effects on energized ion fluxes in the presence of valinomycin.\n",
            "\n",
            "['[CLS]', 'action', 'of', 'propranolol', 'on', 'mitochondrial', 'functions', '-', '-', 'effects', 'on', 'energized', 'ion', 'fluxes', 'in', 'the', 'presence', 'of', 'valinomycin', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O']\n",
            "================================================================================\n",
            "Malathion A and B esterases of mouse liver-I.\n",
            "\n",
            "['[CLS]', 'malathion', 'a', 'and', 'b', 'esterases', 'of', 'mouse', 'liver', '-', 'i', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Increase in acetyl CoA synthetase activity after phenobarbital treatment.\n",
            "\n",
            "['[CLS]', 'increase', 'in', 'acetyl', 'coa', 'synthetase', 'activity', 'after', 'phenobarbital', 'treatment', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'B-Chemical', 'I-Chemical', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Inhibition of aldehyde reductase by acidic metabolites of the biogenic amines.\n",
            "\n",
            "['[CLS]', 'inhibition', 'of', 'aldehyde', 'reductase', 'by', 'acidic', 'metabolites', 'of', 'the', 'biogenic', 'amines', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O']\n",
            "================================================================================\n",
            "Effects of 5,6-dihydroxytryptamine on tyrosine-hydroxylase activity in central catecholaminergic neurons of the rat.\n",
            "\n",
            "['[CLS]', 'effects', 'of', '5', ',', '6', '-', 'dihydroxytryptamine', 'on', 'tyrosine', '-', 'hydroxylase', 'activity', 'in', 'central', 'catecholaminergic', 'neurons', 'of', 'the', 'rat', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'B-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Inhibition of aldehyde reductase isoenzymes in human and rat brain.\n",
            "\n",
            "['[CLS]', 'inhibition', 'of', 'aldehyde', 'reductase', 'isoenzymes', 'in', 'human', 'and', 'rat', 'brain', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Antidepressant drugs affect dopamine uptake.\n",
            "\n",
            "['[CLS]', 'antidepressant', 'drugs', 'affect', 'dopamine', 'uptake', '.', '[SEP]']\n",
            "['O', 'B-Chemical', 'O', 'O', 'B-Chemical', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Aggregation of blood platelets by adrenaline and its uptake.\n",
            "\n",
            "['[CLS]', 'aggregation', 'of', 'blood', 'platelets', 'by', 'adrenaline', 'and', 'its', 'uptake', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "[Biochemical studies on camomile components/III. In vitro studies about the antipeptic activity of (--)-alpha-bisabolol (author's transl)].\n",
            "\n",
            "['[CLS]', '[', 'biochemical', 'studies', 'on', 'camomile', 'components', '/', 'iii', '.', 'in', 'vitro', 'studies', 'about', 'the', 'antipeptic', 'activity', 'of', '(', '-', '-', ')', '-', 'alpha', '-', 'bisabolol', '(', 'author', \"'\", 's', 'transl', ')', ']', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "(--)-alpha-Bisabolol has a primary antipeptic action depending on dosage, which is not caused by an alteration of the pH-value. The proteolytic activity of pepsin is reduced by 50 percent through addition of bisabolol in the ratio of 1/0.5. The antipeptic action of bisabolol only occurs in case of direct contact. In case of a previous contact with the substrate, the inhibiting effect is lost.\n",
            "\n",
            "['[CLS]', '(', '-', '-', ')', '-', 'alpha', '-', 'bisabolol', 'has', 'a', 'primary', 'antipeptic', 'action', 'depending', 'on', 'dosage', ',', 'which', 'is', 'not', 'caused', 'by', 'an', 'alteration', 'of', 'the', 'ph', '-', 'value', '.', 'the', 'proteolytic', 'activity', 'of', 'pepsin', 'is', 'reduced', 'by', '50', 'percent', 'through', 'addition', 'of', 'bisabolol', 'in', 'the', 'ratio', 'of', '1', '/', '0', '.', '5', '.', 'the', 'antipeptic', 'action', 'of', 'bisabolol', 'only', 'occurs', 'in', 'case', 'of', 'direct', 'contact', '.', 'in', 'case', 'of', 'a', 'previous', 'contact', 'with', 'the', 'substrate', ',', 'the', 'inhibiting', 'effect', 'is', 'lost', '.', '[SEP]']\n",
            "['O', 'B-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "[Demonstration of tumor inhibiting properties of a strongly immunostimulating low-molecular weight substance. Comparative studies with ifosfamide on the immuno-labile DS carcinosarcoma. Stimulation of the autoimmune activity for approx. 20 days by BA 1, a N-(2-cyanoethylene)-urea. Novel prophylactic possibilities].\n",
            "\n",
            "['[CLS]', '[', 'demonstration', 'of', 'tumor', 'inhibiting', 'properties', 'of', 'a', 'strongly', 'immunostimulating', 'low', '-', 'molecular', 'weight', 'substance', '.', 'comparative', 'studies', 'with', 'ifosfamide', 'on', 'the', 'immuno', '-', 'labile', 'ds', 'carcinosarcoma', '.', 'stimulation', 'of', 'the', 'autoimmune', 'activity', 'for', 'approx', '.', '20', 'days', 'by', 'ba', '1', ',', 'a', 'n', '-', '(', '2', '-', 'cyanoethylene', ')', '-', 'urea', '.', 'novel', 'prophylactic', 'possibilities', ']', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'I-Chemical', 'O', 'O', 'B-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "A report is given on the recent discovery of outstanding immunological properties in BA 1 [N-(2-cyanoethylene)-urea] having a (low) molecular mass M = 111.104. Experiments in 214 DS carcinosarcoma bearing Wistar rats have shown that BA 1, at a dosage of only about 12 percent LD50 (150 mg kg) and negligible lethality (1.7 percent), results in a recovery rate of 40 percent without hyperglycemia and, in one test, of 80 percent with hyperglycemia. Under otherwise unchanged conditions the reference substance ifosfamide (IF) -- a further development of cyclophosphamide -- applied without hyperglycemia in its most efficient dosage of 47 percent LD50 (150 mg kg) brought about a recovery rate of 25 percent at a lethality of 18 percent. (Contrary to BA 1, 250-min hyperglycemia caused no further improvement of the recovery rate.) However this comparison is characterized by the fact that both substances exhibit two quite different (complementary) mechanisms of action. Leucocyte counts made after application of the said cancerostatics and dosages have shown a pronounced stimulation with BA 1 and with ifosfamide, the known suppression in the post-therapeutic interval usually found with standard cancerostatics. In combination with the cited plaque test for BA 1, blood pictures then allow conclusions on the immunity status. Since IF can be taken as one of the most efficient cancerostatics--there is no other chemotherapeutic known up to now that has a more significant effect on the DS carcinosarcoma in rats -- these findings are of special importance. Finally, the total amount of leucocytes and lymphocytes as well as their time behaviour was determined from the blood picture of tumour-free rats after i.v. application of BA 1. The thus obtained numerical values clearly show that further research work on the prophylactic use of this substance seems to be necessary and very promising.\n",
            "\n",
            "['[CLS]', 'a', 'report', 'is', 'given', 'on', 'the', 'recent', 'discovery', 'of', 'outstanding', 'immunological', 'properties', 'in', 'ba', '1', '[', 'n', '-', '(', '2', '-', 'cyanoethylene', ')', '-', 'urea', ']', 'having', 'a', '(', 'low', ')', 'molecular', 'mass', 'm', '=', '111', '.', '104', '.', 'experiments', 'in', '214', 'ds', 'carcinosarcoma', 'bearing', 'wistar', 'rats', 'have', 'shown', 'that', 'ba', '1', ',', 'at', 'a', 'dosage', 'of', 'only', 'about', '12', 'percent', 'ld50', '(', '150', 'mg', 'kg', ')', 'and', 'negligible', 'lethality', '(', '1', '.', '7', 'percent', ')', ',', 'results', 'in', 'a', 'recovery', 'rate', 'of', '40', 'percent', 'without', 'hyperglycemia', 'and', ',', 'in', 'one', 'test', ',', 'of', '80', 'percent', 'with', 'hyperglycemia', '.', 'under', 'otherwise', 'unchanged', 'conditions', 'the', 'reference', 'substance', 'ifosfamide', '(', 'if', ')', '-', '-', 'a', 'further', 'development', 'of', 'cyclophosphamide', '-', '-', 'applied', 'without', 'hyperglycemia', 'in', 'its', 'most', 'efficient', 'dosage', 'of', '47', 'percent', 'ld50', '(', '150', 'mg', 'kg', ')', 'brought', 'about', 'a', 'recovery', 'rate', 'of', '25', 'percent', 'at', 'a', 'lethality', 'of', '18', 'percent', '.', '(', 'contrary', 'to', 'ba', '1', ',', '250', '-', 'min', 'hyperglycemia', 'caused', 'no', 'further', 'improvement', 'of', 'the', 'recovery', 'rate', '.', ')', 'however', 'this', 'comparison', 'is', 'characterized', 'by', 'the', 'fact', 'that', 'both', 'substances', 'exhibit', 'two', 'quite', 'different', '(', 'complementary', ')', 'mechanisms', 'of', 'action', '.', 'leucocyte', 'counts', 'made', 'after', 'application', 'of', 'the', 'said', 'cancerostatics', 'and', 'dosages', 'have', 'shown', 'a', 'pronounced', 'stimulation', 'with', 'ba', '1', 'and', 'with', 'ifosfamide', ',', 'the', 'known', 'suppression', 'in', 'the', 'post', '-', 'therapeutic', 'interval', 'usually', 'found', 'with', 'standard', 'cancerostatics', '.', 'in', 'combination', 'with', 'the', 'cited', 'plaque', 'test', 'for', 'ba', '1', ',', 'blood', 'pictures', 'then', 'allow', 'conclusions', 'on', 'the', 'immunity', 'status', '.', 'since', 'if', 'can', 'be', 'taken', 'as', 'one', 'of', 'the', 'most', 'efficient', 'cancerostatics', '-', '-', 'there', 'is', 'no', 'other', 'chemotherapeutic', 'known', 'up', 'to', 'now', 'that', 'has', 'a', 'more', 'significant', 'effect', 'on', 'the', 'ds', 'carcinosarcoma', 'in', 'rats', '-', '-', 'these', 'findings', 'are', 'of', 'special', 'importance', '.', 'finally', ',', 'the', 'total', 'amount', 'of', 'leucocytes', 'and', 'lymphocytes', 'as', 'well', 'as', 'their', 'time', 'behaviour', 'was', 'determined', 'from', 'the', 'blood', 'picture', 'of', 'tumour', '-', 'free', 'rats', 'after', 'i', '.', 'v', '.', 'application', 'of', 'ba', '1', '.', 'the', 'thus', 'obtained', 'numerical', 'values', 'clearly', 'show', 'that', 'further', 'research', 'work', 'on', 'the', 'prophylactic', 'use', 'of', 'this', 'substance', 'seems', 'to', 'be', 'necessary', 'and', 'very', 'promising', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'I-Chemical', 'O', 'B-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Effect of etafenone on total and regional myocardial blood flow.\n",
            "\n",
            "['[CLS]', 'effect', 'of', 'etafenone', 'on', 'total', 'and', 'regional', 'myocardial', 'blood', 'flow', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "The distribution of blood flow to the subendocardial, medium and subepicardial layers of the left ventricular free wall was studied in anaesthetized dogs under normoxic (A), hypoxic (B) conditions and under pharmacologically induced (etafenone) coronary vasodilation (C). Regional myocardial blood flow was determined by means of the particle distribution method. In normoxia a transmural gradient of flow was observed, with the subendocardial layers receiving a significantly higher flow rate compared with the subepicardial layers. In hypoxia induced vasodilation this transmural gradient of flow was persistent. In contrast a marked redistribution of regional flow was observed under pharmacologically induced vasodilation. The transmural gradient decreased. In contrast to some findings these experiments demonstrate that a considerable vasodilatory capacity exists in all layers of the myocardium and can be utilized by drugs. The differences observed for the intramural distribution pattern of flow under hypoxia and drug induced vasodilation support the hypothesis that this pattern reflects corresponding gradients of regional myocardial metabolism.\n",
            "\n",
            "['[CLS]', 'the', 'distribution', 'of', 'blood', 'flow', 'to', 'the', 'subendocardial', ',', 'medium', 'and', 'subepicardial', 'layers', 'of', 'the', 'left', 'ventricular', 'free', 'wall', 'was', 'studied', 'in', 'anaesthetized', 'dogs', 'under', 'normoxic', '(', 'a', ')', ',', 'hypoxic', '(', 'b', ')', 'conditions', 'and', 'under', 'pharmacologically', 'induced', '(', 'etafenone', ')', 'coronary', 'vasodilation', '(', 'c', ')', '.', 'regional', 'myocardial', 'blood', 'flow', 'was', 'determined', 'by', 'means', 'of', 'the', 'particle', 'distribution', 'method', '.', 'in', 'normoxia', 'a', 'transmural', 'gradient', 'of', 'flow', 'was', 'observed', ',', 'with', 'the', 'subendocardial', 'layers', 'receiving', 'a', 'significantly', 'higher', 'flow', 'rate', 'compared', 'with', 'the', 'subepicardial', 'layers', '.', 'in', 'hypoxia', 'induced', 'vasodilation', 'this', 'transmural', 'gradient', 'of', 'flow', 'was', 'persistent', '.', 'in', 'contrast', 'a', 'marked', 'redistribution', 'of', 'regional', 'flow', 'was', 'observed', 'under', 'pharmacologically', 'induced', 'vasodilation', '.', 'the', 'transmural', 'gradient', 'decreased', '.', 'in', 'contrast', 'to', 'some', 'findings', 'these', 'experiments', 'demonstrate', 'that', 'a', 'considerable', 'vasodilatory', 'capacity', 'exists', 'in', 'all', 'layers', 'of', 'the', 'myocardium', 'and', 'can', 'be', 'utilized', 'by', 'drugs', '.', 'the', 'differences', 'observed', 'for', 'the', 'intramural', 'distribution', 'pattern', 'of', 'flow', 'under', 'hypoxia', 'and', 'drug', 'induced', 'vasodilation', 'support', 'the', 'hypothesis', 'that', 'this', 'pattern', 'reflects', 'corresponding', 'gradients', 'of', 'regional', 'myocardial', 'metabolism', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Influence of a new virostatic compound on the induction of enzymes in rat liver.\n",
            "\n",
            "['[CLS]', 'influence', 'of', 'a', 'new', 'virostatic', 'compound', 'on', 'the', 'induction', 'of', 'enzymes', 'in', 'rat', 'liver', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "The virostatic compound N,N-diethyl-4-[2-(2-oxo-3-tetradecyl-1-imidazolidinyl)-ethyl]-1-piperazinecarboxamide-hydrochloride (5531) was analyzed as to its effect on the induction of tryptophan-pyrrolase and tyrosineaminotransferase in rat liver. 1. The basic activity of the enzymes was not influenced by the substance either in normal or in adrenalectomized animals. 2. The induction of the enzymes by cortisone increased in the presence of the compound whereas the substrate induction remained unchanged. 3. The induction of tyrosine-aminotransferase by dexamethasonephosphate in tissue culture is inhibited if the dose of compound 5531 is higher than 5 mug/ml.\n",
            "\n",
            "['[CLS]', 'the', 'virostatic', 'compound', 'n', ',', 'n', '-', 'diethyl', '-', '4', '-', '[', '2', '-', '(', '2', '-', 'oxo', '-', '3', '-', 'tetradecyl', '-', '1', '-', 'imidazolidinyl', ')', '-', 'ethyl', ']', '-', '1', '-', 'piperazinecarboxamide', '-', 'hydrochloride', '(', '5531', ')', 'was', 'analyzed', 'as', 'to', 'its', 'effect', 'on', 'the', 'induction', 'of', 'tryptophan', '-', 'pyrrolase', 'and', 'tyrosineaminotransferase', 'in', 'rat', 'liver', '.', '1', '.', 'the', 'basic', 'activity', 'of', 'the', 'enzymes', 'was', 'not', 'influenced', 'by', 'the', 'substance', 'either', 'in', 'normal', 'or', 'in', 'adrenalectomized', 'animals', '.', '2', '.', 'the', 'induction', 'of', 'the', 'enzymes', 'by', 'cortisone', 'increased', 'in', 'the', 'presence', 'of', 'the', 'compound', 'whereas', 'the', 'substrate', 'induction', 'remained', 'unchanged', '.', '3', '.', 'the', 'induction', 'of', 'tyrosine', '-', 'aminotransferase', 'by', 'dexamethasonephosphate', 'in', 'tissue', 'culture', 'is', 'inhibited', 'if', 'the', 'dose', 'of', 'compound', '5531', 'is', 'higher', 'than', '5', 'mug', '/', 'ml', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'B-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'O', 'I-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'I-Chemical', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'I-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "Pharmacological properties of new neuroleptic compounds.\n",
            "\n",
            "['[CLS]', 'pharmacological', 'properties', 'of', 'new', 'neuroleptic', 'compounds', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n",
            "RMI 61 140, RMI 61 144 and RMI 61 280 are newly synthetized N-[8-R-dibenzo(b,f)oxepin-10-yl]-N'-methyl-piperazine-maleates which show interesting psychopharmacologic effects. This work contains the results of a study performed with these three compounds, in order to demonstrate their neuropsycholeptic activity in comparison with chloropromazine (CPZ) and chlordiazepoxide (CPD). The inhibition of motility observed in mice shows that the compounds reduce the normal spontaneous motility as well as the muscle tone. The central-depressant activity is evidenced by increased barbiturate-induced sleep and a remarkable eyelid ptosis can also be observed. Our compounds do not show any activity on electroshock just as do CPZ and CPD. As to the antipsychotic outline, our compounds show strong reduction of lethality due to amphetamine in grouped mice and a strong antiapomorphine activity. They show also an antiaggressive effect and an inhibitory activity on avoidance behaviour much stronger than CPZ. We have also found extrapyramidal effects, as catalepsy, common to many tranquillizers of the kind of the standards used by us. As for vegetative phenomena, the compounds show hypotensive dose related action ranging from moderate to strong, probably due to an a-receptor inhibition. Adrenolytic activity against lethal doses of adrenaline, antiserotonin and antihistaminic effects, as well as other actions (hypothermia, analgesia, etc.) confirm that RMI 61 140, RMI 61 144 and RMI 61 280 are endowed with pharmacologic properties similar and more potent than those of CPZ. Studies on the metabolism of brain catecholamines show that they are similar to CPZ, although with less effect on dopamine level.\n",
            "\n",
            "['[CLS]', 'rmi', '61', '140', ',', 'rmi', '61', '144', 'and', 'rmi', '61', '280', 'are', 'newly', 'synthetized', 'n', '-', '[', '8', '-', 'r', '-', 'dibenzo', '(', 'b', ',', 'f', ')', 'oxepin', '-', '10', '-', 'yl', ']', '-', 'n', \"'\", '-', 'methyl', '-', 'piperazine', '-', 'maleates', 'which', 'show', 'interesting', 'psychopharmacologic', 'effects', '.', 'this', 'work', 'contains', 'the', 'results', 'of', 'a', 'study', 'performed', 'with', 'these', 'three', 'compounds', ',', 'in', 'order', 'to', 'demonstrate', 'their', 'neuropsycholeptic', 'activity', 'in', 'comparison', 'with', 'chloropromazine', '(', 'cpz', ')', 'and', 'chlordiazepoxide', '(', 'cpd', ')', '.', 'the', 'inhibition', 'of', 'motility', 'observed', 'in', 'mice', 'shows', 'that', 'the', 'compounds', 'reduce', 'the', 'normal', 'spontaneous', 'motility', 'as', 'well', 'as', 'the', 'muscle', 'tone', '.', 'the', 'central', '-', 'depressant', 'activity', 'is', 'evidenced', 'by', 'increased', 'barbiturate', '-', 'induced', 'sleep', 'and', 'a', 'remarkable', 'eyelid', 'ptosis', 'can', 'also', 'be', 'observed', '.', 'our', 'compounds', 'do', 'not', 'show', 'any', 'activity', 'on', 'electroshock', 'just', 'as', 'do', 'cpz', 'and', 'cpd', '.', 'as', 'to', 'the', 'antipsychotic', 'outline', ',', 'our', 'compounds', 'show', 'strong', 'reduction', 'of', 'lethality', 'due', 'to', 'amphetamine', 'in', 'grouped', 'mice', 'and', 'a', 'strong', 'antiapomorphine', 'activity', '.', 'they', 'show', 'also', 'an', 'antiaggressive', 'effect', 'and', 'an', 'inhibitory', 'activity', 'on', 'avoidance', 'behaviour', 'much', 'stronger', 'than', 'cpz', '.', 'we', 'have', 'also', 'found', 'extrapyramidal', 'effects', ',', 'as', 'catalepsy', ',', 'common', 'to', 'many', 'tranquillizers', 'of', 'the', 'kind', 'of', 'the', 'standards', 'used', 'by', 'us', '.', 'as', 'for', 'vegetative', 'phenomena', ',', 'the', 'compounds', 'show', 'hypotensive', 'dose', 'related', 'action', 'ranging', 'from', 'moderate', 'to', 'strong', ',', 'probably', 'due', 'to', 'an', 'a', '-', 'receptor', 'inhibition', '.', 'adrenolytic', 'activity', 'against', 'lethal', 'doses', 'of', 'adrenaline', ',', 'antiserotonin', 'and', 'antihistaminic', 'effects', ',', 'as', 'well', 'as', 'other', 'actions', '(', 'hypothermia', ',', 'analgesia', ',', 'etc', '.', ')', 'confirm', 'that', 'rmi', '61', '140', ',', 'rmi', '61', '144', 'and', 'rmi', '61', '280', 'are', 'endowed', 'with', 'pharmacologic', 'properties', 'similar', 'and', 'more', 'potent', 'than', 'those', 'of', 'cpz', '.', 'studies', 'on', 'the', 'metabolism', 'of', 'brain', 'catecholamines', 'show', 'that', 'they', 'are', 'similar', 'to', 'cpz', ',', 'although', 'with', 'less', 'effect', 'on', 'dopamine', 'level', '.', '[SEP]']\n",
            "['O', 'B-Chemical', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'I-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'B-Chemical', 'O', 'O', 'B-Chemical', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O']\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/nlpProjectNew/results.txt'\n",
        "\n",
        "with open(file_path, \"w\") as file:\n",
        "    for i in range(len(file_contents[:100000])):\n",
        "        # print(file_contents[i])\n",
        "        sent, label = get_results(file_contents[i][:512])\n",
        "        for i in range(1, min(len(sent), len(label))-1):\n",
        "            file.write(f\"{sent[i]}  {label[i]}\\n\")\n",
        "        # file.write(\"=\"*80)\n",
        "        file.write('\\n')"
      ],
      "metadata": {
        "id": "dif2oyOpXAEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cpu'\n",
        "final_active_logits_noise = []\n",
        "final_active_labels_noise = []\n",
        "for step, batch in (enumerate(weak_loader)):\n",
        "    # Extract individual tensors from the batch dictionary\n",
        "    # print(np.array(input_ids).shape)\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    token_type_ids = batch['token_type_ids'].to(device)\n",
        "    label_ids = batch['labels'].to(device)\n",
        "    features = batch['features'].to(device)\n",
        "    predict_mask = batch['predict_mask'].to(device)\n",
        "    weights = batch['weights'].to(device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model1(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
        "\n",
        "\n",
        "    active_loss = attention_mask.view(-1) == 1\n",
        "    active_logits = logits.view(-1, num_labels)\n",
        "    active_labels = torch.where(\n",
        "        active_loss,\n",
        "        label_ids.view(-1),\n",
        "        torch.tensor(loss_fn.ignore_index).type_as(label_ids)\n",
        "    )\n",
        "    active_logits = active_logits.cpu().detach().numpy()\n",
        "    active_labels = active_labels.cpu().detach().numpy()\n",
        "    # print(active_logits.shape, active_labels.shape)\n",
        "    final_active_labels.extend(active_labels)\n",
        "    final_active_logits_noise.extend(active_logits)\n",
        "\n",
        "\n",
        "pred_logits_noise = np.argmax(final_active_logits_noise, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_ICpCGwvApD",
        "outputId": "62dc2086-3eba-4921-8a9f-542f0021194d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(375778,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred_logits_noise.shape)\n",
        "pred_logits_noise[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZm3guj0vwfY",
        "outputId": "77419b1c-0342-41f3-c435-d868fa4a6e19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11482,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_loader = DataLoader(\n",
        "#     dataset=train_dataset,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=True,\n",
        "#     collate_fn=train_dataset.dynamic_collator(tokenizer.pad_token_id),\n",
        "# )"
      ],
      "metadata": {
        "id": "ytk5Dj89iKl9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weak_loader = DataLoader(\n",
        "    dataset=weak_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    collate_fn=weak_dataset.dynamic_collator(tokenizer.pad_token_id),\n",
        ")"
      ],
      "metadata": {
        "id": "VaA7fR3n8wSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "model1 = model1.to('cpu')\n",
        "def get_results_noise(weak_loader):\n",
        "    # text = \" \".join(test_examples[56].words)\n",
        "\n",
        "    # tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n",
        "    tagged_words = []\n",
        "    real_label_id = []\n",
        "\n",
        "    # input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    for i, batch in enumerate(weak_loader):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        token_type_ids = batch['token_type_ids']\n",
        "        label_ids = batch['labels']\n",
        "        features = batch['features']\n",
        "        predict_mask = batch['predict_mask']\n",
        "        weights = batch['weights']\n",
        "\n",
        "\n",
        "        # input_ids = torch.tensor(input_ids).unsqueeze(0).to('cpu')  # Move input tensors to the CPU\n",
        "        # attention_mask = torch.tensor(attention_mask).unsqueeze(0).to('cpu')\n",
        "        # token_type_ids = torch.tensor(token_type_ids).unsqueeze(0).to('cpu')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model1(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
        "\n",
        "        predicted_label_ids = torch.argmax(logits, dim=2).squeeze().tolist()\n",
        "\n",
        "\n",
        "        current_word = \"\"\n",
        "        current_label = \"\"\n",
        "        for token, predicted_label_id, labe in zip(tokens, predicted_label_ids, label_ids):\n",
        "            label = list(label_map.keys())[list(label_map.values()).index(predicted_label_id)]\n",
        "\n",
        "            if token.startswith(\"##\"):\n",
        "                current_word += token[2:]\n",
        "            else:\n",
        "                if current_word:\n",
        "                    tagged_words.append((current_word, current_label))\n",
        "                current_word = token\n",
        "                current_label = label\n",
        "                real_label_id.append(labe)\n",
        "\n",
        "        if current_word:\n",
        "            tagged_words.append((current_word, current_label))\n",
        "\n",
        "    words = []\n",
        "    tags = []\n",
        "    for word, label in tagged_words:\n",
        "        words.append(word)\n",
        "        tags.append(label)\n",
        "    return words, tags, real_label_id\n"
      ],
      "metadata": {
        "id": "n6X5gzEKiK_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weak_data_sent, waek_data_labels, real_label_id= get_results_noise(weak_loader)\n"
      ],
      "metadata": {
        "id": "FvD7NcC17Ata"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(weak_data_sent), weak_data_sent[0:50])\n",
        "print(len(waek_data_labels), waek_data_labels[:50])\n",
        "print(len(real_label_id), np.array(real_label_id[:50]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtdegfN89dLj",
        "outputId": "ffc67283-223a-45f5-a691-68a389d0dfff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126 [CLS]\n",
            "126 ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "126 [tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    1,    2,    2,    2,    2,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
            "           0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
            "           0,    2,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,\n",
            "        -100]), tensor([-100,    1,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,\n",
            "           0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           1,    0,    0,    0,    2,    2,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    1,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0, -100]), tensor([-100,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    1,    2,    2,    0,    0,    0,    0,    0,    0,    0,\n",
            "           1,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,\n",
            "           0,    0, -100]), tensor([-100,    0,    0,    1,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    1,    0,    0,    0,    1,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    1,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0, -100]), tensor([-100,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,\n",
            "           0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           1,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
            "           0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,\n",
            "           0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    1,    2,    2,    0,    0,    0,    0,\n",
            "           0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    1,\n",
            "           0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    1,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,\n",
            "           0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,\n",
            "           0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    1,    2,    2,    0,    0,    2,    2,    2,    2,    2,\n",
            "           2,    2,    2,    0,    2,    2,    2,    2,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    1,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    1,    0,    2,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    1,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           1,    0,    0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    1,    2,    2,    0,    0,    0,    0,    0,    1,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0, -100]), tensor([-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    1,    2,    0,    0, -100]), tensor([-100,    0,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0, -100])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(tags)):\n",
        "    if(final_active_labels_noise[i] == 0 and tags[i] != 0):\n",
        "        final_labels_noise[i] = final_pred_logits_noise[i]\n",
        "return words, final_labels_noise"
      ],
      "metadata": {
        "id": "BALhsKJp9Zc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pred_logits_noise = pred_logits\n",
        "final_active_labels_noise = final_active_labels\n",
        "final_labels_noise = final_active_labels"
      ],
      "metadata": {
        "id": "E0y8YOBPjxeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i in range(final_active_logits_noise):\n",
        "#     if(final_active_labels_noise[i] == 0 and final_pred_logits_noise[i] != 0):\n",
        "#         final_labels_noise[i] = final_pred_logits_noise[i]\n"
      ],
      "metadata": {
        "id": "Z8eUlQ3Pj11I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/nlpProjectNew/noise_removed.txt'\n",
        "\n",
        "with open(file_path, \"w\") as file:\n",
        "    for i in range(len(file_contents[:100000])):\n",
        "        # print(file_contents[i])\n",
        "        sent, label = get_results(file_contents[i][:512])\n",
        "        for i in range(1, min(len(sent), len(label))-1):\n",
        "            file.write(f\"{sent[i]}  {label[i]}\\n\")\n",
        "        # file.write(\"=\"*80)\n",
        "        file.write('\\n')"
      ],
      "metadata": {
        "id": "HO-p981_gny9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e9JYfrb_mPvb"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}