{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "M5nZ0JSDuuO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f0f86ef-40cb-4f2e-dc33-18dee98490ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import pickle\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "import nltk.data\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from collections import defaultdict, OrderedDict\n",
        "import regex as re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKnF5gCYuuPC",
        "outputId": "76abf6d0-d951-4653-898d-281fbc7c247a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lpcbw5-fuuPF"
      },
      "outputs": [],
      "source": [
        "folder_path_chemical = \"/content/drive/My Drive/nlp project/m_proj/BC5CDR-chem-IOBES\"\n",
        "file_path_chemical = os.path.join(folder_path_chemical, \"train.tsv\")\n",
        "\n",
        "parsed_data_chemical = []  # Create a list to store parsed JSON objects\n",
        "\n",
        "with open(file_path_chemical, encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        # temp = json.loads(line)\n",
        "        parsed_data_chemical.append(line)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "174NO8mVuuPH"
      },
      "outputs": [],
      "source": [
        "# parsed_data_chemical[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "N_Hv8u1fuuPK"
      },
      "outputs": [],
      "source": [
        "sentences_chemical = []\n",
        "labels_chemical = []\n",
        "sentence_temp_chemical = []\n",
        "label_temp_chemical = []\n",
        "\n",
        "for data in parsed_data_chemical:\n",
        "    # print(data)\n",
        "    if(data == '\\n'):\n",
        "        # print(\"entered\")\n",
        "        sentences_chemical.append(sentence_temp_chemical)\n",
        "        labels_chemical.append(label_temp_chemical)\n",
        "        sentence_temp_chemical = []\n",
        "        label_temp_chemical = []\n",
        "        continue\n",
        "    # print(data)\n",
        "    word, label = data.strip().split('\\t')\n",
        "    sentence_temp_chemical.append(word)\n",
        "    label_temp_chemical.append(label)\n",
        "    # print(word, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1QTSNUBNuuPL",
        "outputId": "2f832c68-5a5f-4442-9972-dfc220b1bcb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4559"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(sentences_chemical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3STKTZiuuPM",
        "outputId": "eaf51f2b-8f99-4126-fd7f-49adcd9df28c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Selegiline\\tO\\n', '-\\tO\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "folder_path_disease = \"/content/drive/My Drive/nlp project/m_proj/BC5CDR-disease-IOBES\"\n",
        "file_path_disease = os.path.join(folder_path_disease, \"train.tsv\")\n",
        "\n",
        "parsed_data_disease = []  # Create a list to store parsed JSON objects\n",
        "\n",
        "with open(file_path_disease, encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        # temp = json.loads(line)\n",
        "        parsed_data_disease.append(line)\n",
        "\n",
        "parsed_data_disease[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TjN-rTXbuuPN"
      },
      "outputs": [],
      "source": [
        "sentences_disease = []\n",
        "labels_disease = []\n",
        "sentence_temp_disease = []\n",
        "label_temp_disease = []\n",
        "\n",
        "for data in parsed_data_disease:\n",
        "    # print(data)\n",
        "    if(data == '\\n'):\n",
        "        # print(\"entered\")\n",
        "        sentences_disease.append(sentence_temp_disease)\n",
        "        labels_disease.append(label_temp_disease)\n",
        "        sentence_temp_disease = []\n",
        "        label_temp_disease = []\n",
        "        continue\n",
        "    # print(data)\n",
        "    word, label = data.strip().split('\\t')\n",
        "    sentence_temp_disease.append(word)\n",
        "    label_temp_disease.append(label)\n",
        "    # print(word, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rx5uTaqPuuPP",
        "outputId": "c9173a0c-bd18-4ba4-d3da-513867ce0714"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Selegiline', '-', 'induced', 'postural', 'hypotension', 'in', 'Parkinson', \"'\", 's', 'disease', ':', 'a', 'longitudinal', 'study', 'on', 'the', 'effects', 'of', 'drug', 'withdrawal', '.'], ['OBJECTIVES', ':', 'The', 'United', 'Kingdom', 'Parkinson', \"'\", 's', 'Disease', 'Research', 'Group', '(', 'UKPDRG', ')', 'trial', 'found', 'an', 'increased', 'mortality', 'in', 'patients', 'with', 'Parkinson', \"'\", 's', 'disease', '(', 'PD', ')', 'randomized', 'to', 'receive', '10', 'mg', 'selegiline', 'per', 'day', 'and', 'L', '-', 'dopa', 'compared', 'with', 'those', 'taking', 'L', '-', 'dopa', 'alone', '.'], ['Recently', ',', 'we', 'found', 'that', 'therapy', 'with', 'selegiline', 'and', 'L', '-', 'dopa', 'was', 'associated', 'with', 'selective', 'systolic', 'orthostatic', 'hypotension', 'which', 'was', 'abolished', 'by', 'withdrawal', 'of', 'selegiline', '.'], ['This', 'unwanted', 'effect', 'on', 'postural', 'blood', 'pressure', 'was', 'not', 'the', 'result', 'of', 'underlying', 'autonomic', 'failure', '.'], ['The', 'aims', 'of', 'this', 'study', 'were', 'to', 'confirm', 'our', 'previous', 'findings', 'in', 'a', 'separate', 'cohort', 'of', 'patients', 'and', 'to', 'determine', 'the', 'time', 'course', 'of', 'the', 'cardiovascular', 'consequences', 'of', 'stopping', 'selegiline', 'in', 'the', 'expectation', 'that', 'this', 'might', 'shed', 'light', 'on', 'the', 'mechanisms', 'by', 'which', 'the', 'drug', 'causes', 'orthostatic', 'hypotension', '.']]\n",
            "[['S-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-Chemical', 'O', 'O', 'O', 'B-Chemical', 'I-Chemical', 'E-Chemical', 'O', 'O', 'O', 'O', 'B-Chemical', 'I-Chemical', 'E-Chemical', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-Chemical', 'O', 'B-Chemical', 'I-Chemical', 'E-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-Chemical', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'S-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]\n"
          ]
        }
      ],
      "source": [
        "print(sentences_chemical[:5])\n",
        "print(labels_chemical[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waWt8dteuuPU",
        "outputId": "0c192926-d1ab-4ceb-dd92-df9f2dd3f788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Selegiline', '-', 'induced', 'postural', 'hypotension', 'in', 'Parkinson', \"'\", 's', 'disease', ':', 'a', 'longitudinal', 'study', 'on', 'the', 'effects', 'of', 'drug', 'withdrawal', '.'], ['OBJECTIVES', ':', 'The', 'United', 'Kingdom', 'Parkinson', \"'\", 's', 'Disease', 'Research', 'Group', '(', 'UKPDRG', ')', 'trial', 'found', 'an', 'increased', 'mortality', 'in', 'patients', 'with', 'Parkinson', \"'\", 's', 'disease', '(', 'PD', ')', 'randomized', 'to', 'receive', '10', 'mg', 'selegiline', 'per', 'day', 'and', 'L', '-', 'dopa', 'compared', 'with', 'those', 'taking', 'L', '-', 'dopa', 'alone', '.'], ['Recently', ',', 'we', 'found', 'that', 'therapy', 'with', 'selegiline', 'and', 'L', '-', 'dopa', 'was', 'associated', 'with', 'selective', 'systolic', 'orthostatic', 'hypotension', 'which', 'was', 'abolished', 'by', 'withdrawal', 'of', 'selegiline', '.'], ['This', 'unwanted', 'effect', 'on', 'postural', 'blood', 'pressure', 'was', 'not', 'the', 'result', 'of', 'underlying', 'autonomic', 'failure', '.'], ['The', 'aims', 'of', 'this', 'study', 'were', 'to', 'confirm', 'our', 'previous', 'findings', 'in', 'a', 'separate', 'cohort', 'of', 'patients', 'and', 'to', 'determine', 'the', 'time', 'course', 'of', 'the', 'cardiovascular', 'consequences', 'of', 'stopping', 'selegiline', 'in', 'the', 'expectation', 'that', 'this', 'might', 'shed', 'light', 'on', 'the', 'mechanisms', 'by', 'which', 'the', 'drug', 'causes', 'orthostatic', 'hypotension', '.']]\n",
            "[['O', 'O', 'O', 'B-Disease', 'E-Disease', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'E-Disease', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'E-Disease', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'I-Disease', 'E-Disease', 'O', 'S-Disease', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'I-Disease', 'E-Disease', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Disease', 'E-Disease', 'O']]\n"
          ]
        }
      ],
      "source": [
        "print(sentences_disease[:5])\n",
        "print(labels_disease[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lYJpn9KuuPW",
        "outputId": "37229235-a846-40df-af8a-5b1dea994e9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4559, 4559)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(sentences_chemical), len(sentences_disease)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YG6iHhjluuPY"
      },
      "outputs": [],
      "source": [
        "folder_path = \"/content/drive/My Drive/nlp project/m_proj/BC5CDR-IOBES\"\n",
        "file_path = os.path.join(folder_path, \"train.tsv\")\n",
        "\n",
        "parsed_data = []  # Create a list to store parsed JSON objects\n",
        "\n",
        "with open(file_path, encoding=\"utf-8\") as file:\n",
        "    for line in file:\n",
        "        # temp = json.loads(line)\n",
        "        parsed_data.append(line)\n",
        "\n",
        "parsed_data[:2]\n",
        "\n",
        "sentences = []\n",
        "labels = []\n",
        "sentence_temp = []\n",
        "label_temp = []\n",
        "\n",
        "for data in parsed_data:\n",
        "    # print(data)\n",
        "    if(data == '\\n'):\n",
        "        # print(\"entered\")\n",
        "        sentences.append(sentence_temp)\n",
        "        labels.append(label_temp)\n",
        "        sentence_temp = []\n",
        "        label_temp = []\n",
        "        continue\n",
        "    # print(data)\n",
        "    word, label = data.strip().split('\\t')\n",
        "    sentence_temp.append(word)\n",
        "    label_temp.append(label)\n",
        "    # print(word, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IouRj8c0uuPZ"
      },
      "outputs": [],
      "source": [
        "st_chemical = set()\n",
        "for sent in labels_chemical:\n",
        "    for word in sent:\n",
        "        st_chemical.add(word)\n",
        "\n",
        "st_disease = set()\n",
        "for sent in labels_disease:\n",
        "    for word in sent:\n",
        "        st_disease.add(word)\n",
        "\n",
        "st = set()\n",
        "for sent in labels:\n",
        "    for word in sent:\n",
        "        st.add(word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ag9r413TuuPa",
        "outputId": "2b570c6a-b95d-4ca7-9a43-0db50c7e24b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'E-Disease', 'O', 'B-Disease', 'I-Disease', 'S-Disease'}\n",
            "{'B-Chemical', 'O', 'I-Chemical', 'S-Chemical', 'E-Chemical'}\n",
            "{'E-Disease', 'B-Chemical', 'O', 'B-Disease', 'I-Disease', 'S-Disease', 'I-Chemical', 'S-Chemical', 'E-Chemical'}\n"
          ]
        }
      ],
      "source": [
        "print(st_disease)\n",
        "print(st_chemical)\n",
        "print(st)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "yKfTCsIzuuPa"
      },
      "outputs": [],
      "source": [
        "label2index = {}\n",
        "index2label = {}\n",
        "\n",
        "for i, label in enumerate(st):\n",
        "    label2index[label] = i\n",
        "    index2label[i] = label"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GX4HzFQlWa1Z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqRjo-EuuuPb",
        "outputId": "2627b71c-4cae-4b9e-d00e-814d1dd439be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'E-Disease': 0,\n",
              " 'B-Chemical': 1,\n",
              " 'O': 2,\n",
              " 'B-Disease': 3,\n",
              " 'I-Disease': 4,\n",
              " 'S-Disease': 5,\n",
              " 'I-Chemical': 6,\n",
              " 'S-Chemical': 7,\n",
              " 'E-Chemical': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "label2index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNTRcn6uuuPb",
        "outputId": "6e345c96-5860-4912-fc9a-fb2f9080be76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'E-Disease',\n",
              " 1: 'B-Chemical',\n",
              " 2: 'O',\n",
              " 3: 'B-Disease',\n",
              " 4: 'I-Disease',\n",
              " 5: 'S-Disease',\n",
              " 6: 'I-Chemical',\n",
              " 7: 'S-Chemical',\n",
              " 8: 'E-Chemical'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "index2label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UeaI8pGCuuPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8f784b3-7f49-4696-9f61-cd4d76ae744c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Formate assay in body fluids: application in methanol poisoning.\\n', 'Delineation of the intimate details of the backbone conformation of pyridine nucleotide coenzymes in aqueous solution.\\n', 'Effect of chloroquine on cultured fibroblasts: release of lysosomal hydrolases and inhibition of their uptake.\\n', 'Metal substitutions incarbonic anhydrase: a halide ion probe study.\\n', 'Atomic models for the polypeptide backbones of myohemerythrin and hemerythrin.\\n', 'Studies of oxygen binding energy to hemoglobin molecule.\\n', 'Maturation of the adrenal medulla--IV. Effects of morphine.\\n', 'Comparison between procaine and isocarboxazid metabolism in vitro by a liver microsomal amidase-esterase.\\n', 'Radiochemical assay of glutathione S-epoxide transferase and its enhancement by phenobarbital in rat liver in vivo.\\n', 'Digitoxin metabolism by rat liver microsomes.\\n']\n"
          ]
        }
      ],
      "source": [
        "import gzip\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/nlp project/amazon-weak-ner-needle-main/bio_script/data/unlabeled_data/all_text.txt\"\n",
        "with open(file_path, \"r\") as file:\n",
        "    file_content = file.readlines()\n",
        "\n",
        "print(file_content[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ezKcQUuAuuPe"
      },
      "outputs": [],
      "source": [
        "# train_data = []\n",
        "# for line in file_content:\n",
        "#     line = line.strip().split()\n",
        "#     if(len(line)):\n",
        "#         train_data.append(line)\n",
        "\n",
        "train_data = []\n",
        "for line in file_content:\n",
        "    line = line.strip()\n",
        "    if(len(line)):\n",
        "        train_data.append(line)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPMLwbmycqN-",
        "outputId": "0926b702-783f-427c-9dda-ff178c8b0a41"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2258838"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9-siTi1I3kE",
        "outputId": "67facf2a-3738-49d7-e467-e3b6ca2b918b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Formate assay in body fluids: application in methanol poisoning.',\n",
              " 'Delineation of the intimate details of the backbone conformation of pyridine nucleotide coenzymes in aqueous solution.',\n",
              " 'Effect of chloroquine on cultured fibroblasts: release of lysosomal hydrolases and inhibition of their uptake.',\n",
              " 'Metal substitutions incarbonic anhydrase: a halide ion probe study.',\n",
              " 'Atomic models for the polypeptide backbones of myohemerythrin and hemerythrin.',\n",
              " 'Studies of oxygen binding energy to hemoglobin molecule.',\n",
              " 'Maturation of the adrenal medulla--IV. Effects of morphine.',\n",
              " 'Comparison between procaine and isocarboxazid metabolism in vitro by a liver microsomal amidase-esterase.',\n",
              " 'Radiochemical assay of glutathione S-epoxide transferase and its enhancement by phenobarbital in rat liver in vivo.',\n",
              " 'Digitoxin metabolism by rat liver microsomes.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=[x.lower() for x in train_data]\n",
        "train_data[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGaPWMmG9vnv",
        "outputId": "8f7ba907-4de3-4cc6-f6b1-066c5cdf777d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['formate assay in body fluids: application in methanol poisoning.',\n",
              " 'delineation of the intimate details of the backbone conformation of pyridine nucleotide coenzymes in aqueous solution.',\n",
              " 'effect of chloroquine on cultured fibroblasts: release of lysosomal hydrolases and inhibition of their uptake.',\n",
              " 'metal substitutions incarbonic anhydrase: a halide ion probe study.',\n",
              " 'atomic models for the polypeptide backbones of myohemerythrin and hemerythrin.',\n",
              " 'studies of oxygen binding energy to hemoglobin molecule.',\n",
              " 'maturation of the adrenal medulla--iv. effects of morphine.',\n",
              " 'comparison between procaine and isocarboxazid metabolism in vitro by a liver microsomal amidase-esterase.',\n",
              " 'radiochemical assay of glutathione s-epoxide transferase and its enhancement by phenobarbital in rat liver in vivo.',\n",
              " 'digitoxin metabolism by rat liver microsomes.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/nlp project/amazon-weak-ner-needle-main/bio_script/data/disease_dict.txt', 'r') as f:\n",
        "    list_disease = [val.strip() for val in f if val.strip() != \"\"]\n",
        "with open('/content/drive/MyDrive/nlp project/amazon-weak-ner-needle-main/bio_script/data/chem_dict.txt', 'r') as f:\n",
        "    list_chemical = [val.strip() for val in f if val.strip() != \"\"]\n",
        "\n",
        "list_disease=[val.lower() for val in list_disease]\n",
        "list_chemical=[val.lower() for val in list_chemical]\n",
        "print(list_disease[:10])\n",
        "print(list_chemical[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXjCEPJkLwf1",
        "outputId": "077d370c-22db-4b19-d042-4d714a42b69d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['abnormal audiograms with deficits mostly in the high frequency range of 4,000 to 8,000 hz', 'colorectal, breast, pancreaticobiliary, gastric, renal cell and head and neck cancers', 'rare , sex-linked recessive , dysmyelinating disease of the central nervous system', 'classic ( complete ) lecithin  cholesterol acyltransferase ( lcat ) deficiency', 'glucose-6-phosphate dehydrogenase ( g6pd ; e . c . 1 . 1 . 1 . 49 ) deficiency', 'impairments in learning, attention, inhibitory control, and arousal regulation', 'declines in simple and sustained attention, working memory, and verbal memory', 'diabetic (streptozotocin-induced) and toxic (vincristine-induced) neuropathy', 'complete hypoxanthine-guanine phosphoribosyl-transferase ( hprt ) deficiency', 'absence of hypoxanthine-guanine phosphoribosyltransferase ( hprt ) activity']\n",
            "['tert-butyl-(s)-8-bromo-11,12,13,13a-tetrahydro-9-oxo-9h- imidazo[1,5-a]-pyrrolo-[2,1-c][1,4]benzodiazepine-1-carboxylate', '5 - [ 2- ( 4- ( 3 - fluorobenzylidene ) piperidin-1-yl ) ethyl ] - 4 -(4-fluorophenyl ) thiazole-2-carboxamide', 'n-(trans-3-hydroxy-1,2,3,4-tetrahydro-2-naphthyl)-n-(3-oxo-3-phenyl-2-methylpropyl)-piperazine hydrochloride', '5 - [2- ( 4- ( 3 - fluorobenzylidene) piperidin-1-yl) ethyl] - 4 -(4-fluorophenyl) thiazole-2-carboxamide', '[-]-[5ar,11bs]-4,5,5a,6,7,11b-hexahydro-2-propyl-3-thia-5-+ ++azacyclopent-1- ena[c]phenathrene-9-10-diol', \"[1r, 3s] 3-[1'-admantyl]-1-aminomethyl-3,4-dihydro-5,6-dihydroxy-1h-2-benzo pyran hydrochloride\", '9-[[2-methoxy-4-[(methylsulphonyl)amino]phenyl]amino ] -n,5-dimethyl- 4-acridinecarboxamide', '9-[[2-methoxy-4-[(methylsulphonyl)amino]phenyl]amino] -n,5-dimethyl- 4-acridinecarboxamide', '[4ar-trans]-4,4a,5,6,7,8,8a,9-o-dihydro-5n-propyl-2h-pyrazo lo-3-4-quinoline hydrochloride', '6-chloro-7,8-dihydroxy-3-allyl-1-phenyl-2,3,4,5-tetrahydro-1h-3-benzaze pine hydrobromide']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dict_data = {\"chemical\":list_chemical, \"disease\" : list_disease}\n",
        "dict_data_len = {\"chemical\" : len(list_chemical), \"disease\" : len(list_disease)}"
      ],
      "metadata": {
        "id": "YYvXLpi8-aot"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dict_chemical"
      ],
      "metadata": {
        "id": "eOw2NKa89mKQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_train = train_data[:100000]"
      ],
      "metadata": {
        "id": "IsRx_nDWdJWM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "line = \"This is a sample sentence.\"\n",
        "entity = [\"sample\", \"test\", \"example\"]\n",
        "print(line[16].isalnum(), line[16])\n",
        "\n",
        "# Initialize the index to None\n",
        "index = None\n",
        "\n",
        "# Iterate over each string in entity\n",
        "for e in entity:\n",
        "    # Find the index of the current string in line\n",
        "    e_index = line.find(e)\n",
        "    print(e, e_index)\n",
        "    # If the string is found and it's the first occurrence or it's a closer match\n",
        "    if e_index != -1 and (index is None or e_index < index):\n",
        "        index = e_index\n",
        "\n",
        "# Print the index of the first occurrence (or None if not found)\n",
        "print(\"Index of first occurrence:\", index)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VSDubIp6xKg",
        "outputId": "fca7d4e9-54fd-474d-88b5-a477c8f05bc8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False  \n",
            "sample 10\n",
            "test -1\n",
            "example -1\n",
            "Index of first occurrence: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import chain\n",
        "from tqdm import tqdm\n",
        "def find(small_train, data_type):\n",
        "    labeled_data = []\n",
        "    unlabeled_data = []\n",
        "\n",
        "    for sentence in (small_train):\n",
        "        labels = [\"O\"]*len(sentence)\n",
        "        values = dict_data[data_type]\n",
        "\n",
        "        for dict_word in (values):\n",
        "            dict_word_length = len(dict_word)\n",
        "            index = sentence.find(dict_word)\n",
        "            while index != -1:\n",
        "                not_labelled_till_now = all([l=='O' for l in labels[index : index+dict_word_length]])\n",
        "                partially_labelled = all([l in ['O', 'I-'+data_type, 'B-'+data_type] for l in labels[index:index+dict_word_length]])\n",
        "                contains_start_of_word = labels[index][0] == 'B' and all([l[0]=='I' for l in labels[index+1:index+dict_word_length]])\n",
        "\n",
        "                if contains_start_of_word:\n",
        "                    pass\n",
        "\n",
        "                elif not_labelled_till_now:\n",
        "                    for i in range(1, dict_word_length):\n",
        "                        labels[index+i] = 'I-'+data_type\n",
        "                    labels[index] = 'B-'+data_type\n",
        "                    if index>0 and sentence[index-1] == \"-\":\n",
        "                        new_index = index-1\n",
        "                        while new_index >= 0 and (sentence[new_index].isalnum() or sentence[new_index] == '-'):\n",
        "                            labels[new_index+1] = 'I-'+data_type\n",
        "                            new_index -= 1\n",
        "                        if(new_index != index-1):\n",
        "                            labels[new_index+1] = 'B-'+data_type\n",
        "                    new_index = index+dict_word_length\n",
        "                    while new_index<len(sentence) and (sentence[new_index].isalnum() or sentence[new_index] == '-'):\n",
        "                        labels[new_index] = 'I-'+data_type\n",
        "                        new_index += 1\n",
        "\n",
        "                elif partially_labelled:\n",
        "                    for i in range(index, index+dict_word_length):\n",
        "                        labels[index] = 'I-'+data_type\n",
        "                    new_index = index+dict_word_length\n",
        "                    while new_index<len(sentence) and (sentence[new_index].isalnum() or sentence[new_index] == '-'):\n",
        "                        labels[new_index] = 'I-'+data_type\n",
        "                        new_index += 1\n",
        "\n",
        "                    if labels[index] == 'B-'+data_type or labels[index] == 'O':\n",
        "                        labels[index] = 'B-'+data_type\n",
        "                        new_index = index-1\n",
        "                        while new_index >= 0 and (sentence[new_index].isalnum() or sentence[new_index] == '-'):\n",
        "                            labels[new_index+1] = 'I-'+data_type\n",
        "                            new_index -= 1\n",
        "                        if(new_index != index-1):\n",
        "                            labels[new_index+1] = 'B-'+data_type\n",
        "                index = sentence.find(dict_word, index+1)\n",
        "        unlabeled_data.append([sentence, labels]) if all(l == 'O' for l in labels) else labeled_data.append([sentence, labels])\n",
        "\n",
        "    return labeled_data, unlabeled_data\n"
      ],
      "metadata": {
        "id": "b7GJdtT1I5Nr"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_lines = []\n",
        "unlabeled_lines = []\n",
        "\n",
        "num_chunks = 500\n",
        "chunk_size = len(small_train) // num_chunks + 1\n",
        "\n",
        "for i in tqdm(range(num_chunks)):\n",
        "    start_idx = chunk_size * i\n",
        "    end_idx = min(len(small_train), chunk_size * (i + 1))\n",
        "    # print(len(small_train), chunk_size * (i + 1))\n",
        "    chunk_labeled_lines, chunk_unlabeled_lines = find(small_train[start_idx:end_idx], \"disease\")\n",
        "    labeled_lines.extend(chunk_labeled_lines)\n",
        "    unlabeled_lines.extend(chunk_unlabeled_lines)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kya2QFvXXaCV",
        "outputId": "5c18cef6-9cda-4dd3-9e7b-c16308c22a35"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [03:42<00:00,  2.24it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('/content/drive/MyDrive/nlp project/labeled_lines.pickle', 'wb') as handle:\n",
        "#     pickle.dump(labeled_lines, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# with open('/content/drive/MyDrive/nlp project/unlabeled_lines.pickle', 'wb') as handle:\n",
        "#     pickle.dump(unlabeled_lines, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "oMdYnVJ5URxX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('/content/drive/MyDrive/nlp project/labeled_lines.pickle', 'rb') as file:\n",
        "#     labeled_lines = pickle.load(file)\n",
        "\n",
        "# with open('/content/drive/MyDrive/nlp project/unlabeled_lines.pickle', 'rb') as file:\n",
        "#     unlabeled_lines = pickle.load(file)\n"
      ],
      "metadata": {
        "id": "Dk7Zdm3ytHzj"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labeled_lines), len(unlabeled_lines)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu26nOqqvsVY",
        "outputId": "2e203d2b-3b4b-42d0-c10b-c7caa32bb684"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33038, 66962)"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labeled_lines[10][0])\n",
        "print(labeled_lines[10][1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSt4iU7FToB3",
        "outputId": "d9e748ce-aaa1-4b68-a98a-22d3cc09fe98"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "regulation of nitrogen fixation. nitrogenase-derepressed mutants of klebsiella pneumoniae.\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-disease', 'I-disease', 'I-disease', 'I-disease', 'I-disease', 'I-disease', 'I-disease', 'I-disease', 'I-disease', 'I-disease', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labeled_lines[10][0][::-1])\n",
        "print(labeled_lines[10][1][::-1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw5zkTb6PZQj",
        "outputId": "0edc9091-c4b7-4e6b-eb05-73d0f2c9f456"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".eainomuenp alleisbelk fo stnatum desserpered-esanegortin .noitaxif negortin fo noitaluger\n",
            "['O', 'I-disease', 'I-disease', 'I-disease', 'I-disease', 'I-disease', 'I-disease', 'I-disease', 'I-disease', 'I-disease', 'B-disease', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_lines_chemical = []\n",
        "unlabeled_lines_chemical = []\n",
        "\n",
        "num_chunks = 500\n",
        "chunk_size = len(small_train) // num_chunks + 1\n",
        "\n",
        "for i in tqdm(range(num_chunks)):\n",
        "    start_idx = chunk_size * i\n",
        "    end_idx = min(len(small_train), chunk_size * (i + 1))\n",
        "    # print(len(small_train), chunk_size * (i + 1))\n",
        "    chunk_labeled_lines_chemical, chunk_unlabeled_lines_chemical = f(small_train[start_idx:end_idx], \"chemical\")\n",
        "    labeled_lines_chemical.extend(chunk_labeled_lines_chemical)\n",
        "    unlabeled_lines_chemical.extend(chunk_unlabeled_lines_chemical)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVCPrigSP_Uo",
        "outputId": "eea258ed-9c34-4cbd-a558-fca7144e6b99"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 500/500 [02:05<00:00,  4.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(labeled_lines_chemical), len(unlabeled_lines_chemical))\n",
        "print(labeled_lines_chemical[10][0])\n",
        "print(labeled_lines_chemical[10][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5aKAm0EQGkC",
        "outputId": "8c8a8680-e92f-4367-afe1-f5a441ffdea7"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48520 51480\n",
            "action of propranolol on mitochondrial functions--effects on energized ion fluxes in the presence of valinomycin.\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def helper(token, label):\n",
        "    if label[0][0] == 'B' and all(label_element[0] == 'I' for label_element in label[1:]):\n",
        "        return label[0]\n",
        "    elif all(label_element == 'O' for label_element in label):\n",
        "        return 'O'\n",
        "    elif all(label_element[0] == 'I' for label_element in label):\n",
        "        return label[0]\n",
        "\n",
        "    pos_tags = set()\n",
        "    for synset in wordnet.synsets(token):\n",
        "        if synset.name().split('.')[0] == token:\n",
        "            pos_tags.add(synset.pos())\n",
        "\n",
        "    pos_tags = list(pos_tags)\n",
        "    # print(pos_tags, token)\n",
        "\n",
        "    if len(pos_tags) == 1 and (pos_tags[0] == 'a' or pos_tags[0] == 's'):\n",
        "        return 'O'\n",
        "    elif label[0][0] == 'I':\n",
        "        return label[0]\n",
        "    elif any(label_element[0] == 'B' for label_element in label):\n",
        "        for label_element in label:\n",
        "            if label_element[0] == 'B':return label_element\n",
        "\n",
        "from itertools import groupby\n",
        "\n",
        "\n",
        "def get_final_labels(labelled_data):\n",
        "    all_samples = []\n",
        "    sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "    # sentences = sent_tokenize(text)\n",
        "    for text, label in tqdm(labelled_data):\n",
        "\n",
        "        sentence_spans = [list(s) for s in sent_detector.span_tokenize(text)]\n",
        "        new_sentence_spans = [\n",
        "            points if (points[1] + 1 >= len(text) or label[points[1]] == \"O\") else [points[0], sentence_spans[index + 1][1]]\n",
        "            for index, points in enumerate(sentence_spans)\n",
        "        ]\n",
        "\n",
        "        # print(\"new_sentence_spans :\", new_sentence_spans)\n",
        "        text_label_pairs = [(text[span[0]:span[1]], label[span[0]:span[1]]) for span in new_sentence_spans ]\n",
        "        for sentence, sentence_label in text_label_pairs:\n",
        "            # print(\"sentence : \", sentence)\n",
        "            # print(\"sentence_label : \", sentence_label)\n",
        "            if(sentence):\n",
        "                tokens = [token for token in re.compile(r'([^\\W_]+|.)').split(sentence) if token]\n",
        "            token_label_pairs = []\n",
        "            prev_token_label = 'O'\n",
        "            if all([a==\"O\" for a in sentence_label]):\n",
        "                continue\n",
        "            # offset = 0\n",
        "            # for token in tokens:\n",
        "            #     # print(token)\n",
        "            #     if token != \" \":\n",
        "            #         token_label = sentence_label[offset: offset+len(token)]\n",
        "            #         token_label = helper(token,token_label)\n",
        "            #         if(token_label):\n",
        "            #             prev_token_label = token_label\n",
        "            #             token_label_pairs.append((token,token_label))\n",
        "            #     offset += len(token)\n",
        "            # all_samples.append(token_label_pairs)\n",
        "            offset = 0\n",
        "            all_samples.append(\n",
        "                [(token, helper(token, sentence_label[offset:offset+len(token)]))\n",
        "                for token in tokens if token != \" \" and (offset := offset + len(token))]\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "    return all_samples\n",
        "\n",
        "all_samples = get_final_labels(labeled_lines)"
      ],
      "metadata": {
        "id": "h98DkKKTgal5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Data size\", len(all_samples))\n",
        "# print(\"Example: \", all_samples[4])"
      ],
      "metadata": {
        "id": "Bi7CjZqAZs91"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data size\", len(all_samples))\n",
        "print(\"Example: \", all_samples[4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNilrwyNmiDF",
        "outputId": "3d5b2dac-6cf5-4128-b210-de56d70f8da9"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data size 90544\n",
            "Example:  [('studies', 'O'), ('of', 'O'), ('oxygen', 'B-chemical'), ('binding', 'O'), ('energy', 'O'), ('to', 'O'), ('hemoglobin', 'O'), ('molecule', 'O'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# val = [[0, 109], [110, 185], [186, 236], [237, 281], [282, 316]]\n",
        "\n",
        "# for start, end in enumerate(val):\n",
        "#     print(start, end)\n",
        "# import nltk\n",
        "# from nltk.corpus import wordnet\n",
        "\n",
        "# # Ensure WordNet is downloaded (you only need to do this once)\n",
        "# nltk.download(\"wordnet\")\n",
        "\n",
        "# # Token to analyze\n",
        "# token = \"book\"\n",
        "\n",
        "# # Initialize a set to store POS tags\n",
        "# pos_tags = set()\n",
        "\n",
        "# # Iterate through WordNet synsets for the token\n",
        "# for synset in wordnet.synsets(token):\n",
        "#     if synset.name().split('.')[0] == token:\n",
        "#         # Get and add the POS tag to the set\n",
        "#         pos_tags.add(synset.pos())\n",
        "\n",
        "# # Print the collected POS tags\n",
        "# print(\"POS tags for the token '{}' are: {}\".format(token, pos_tags))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9W5tL7PqPqO",
        "outputId": "937e7c71-a0b3-42b0-8314-e1967860d658"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [0, 109]\n",
            "1 [110, 185]\n",
            "2 [186, 236]\n",
            "3 [237, 281]\n",
            "4 [282, 316]\n",
            "POS tags for the token 'book' are: {'n', 'v'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/nlp project/labeled_lines.pickle', 'wb') as handle:\n",
        "    pickle.dump(labeled_lines, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "bRfoMsTLyx-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/nlp project/all_samples_labeled.pickle', 'wb') as handle:\n",
        "    pickle.dump(all_samples, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "# with open('/content/drive/MyDrive/nlp project/all_samples_unlabeled.pickle', 'wb') as handle:\n",
        "#     pickle.dump(unlabeled_lines, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "5GCkj6r-ybQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Num of sentences: \", len(all_samples))\n",
        "print(\"Example: \", all_samples[1])\n",
        "print(\"Example: \", all_samples[2])\n",
        "print(\"Example: \", all_samples[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-z6q-Vx6sKxX",
        "outputId": "6f355164-0e4b-415b-c74e-ffe149e17c6f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of sentences:  1165120\n",
            "Example:  [('Effect', 'O'), ('of', 'O'), ('chloroquine', 'B-chemical'), ('on', 'O'), ('cultured', 'O'), ('fibroblasts', 'O'), (':', 'O'), ('release', 'O'), ('of', 'O'), ('lysosomal', 'O'), ('hydrolases', 'O'), ('and', 'O'), ('inhibition', 'O'), ('of', 'O'), ('their', 'O'), ('uptake', 'O'), ('.', 'O')]\n",
            "Example:  [('Studies', 'O'), ('of', 'O'), ('oxygen', 'B-chemical'), ('binding', 'O'), ('energy', 'O'), ('to', 'O'), ('hemoglobin', 'O'), ('molecule', 'O'), ('.', 'O')]\n",
            "Example:  [('Effects', 'O'), ('of', 'O'), ('morphine', 'B-chemical'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Example: \", all_samples[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzDnrb1Mx8sW",
        "outputId": "56fdc3bd-8890-48fe-db97-606cf7f4b169"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example:  [('Effects', 'O'), ('of', 'O'), ('5', 'O'), (',', 'O'), ('6', 'O'), ('-', 'O'), ('dihydroxytryptamine', 'O'), ('on', 'O'), ('tyrosine', 'B-chemical'), ('-', 'I-chemical'), ('hydroxylase', 'I-chemical'), ('activity', 'O'), ('in', 'O'), ('central', 'O'), ('catecholaminergic', 'O'), ('neurons', 'O'), ('of', 'O'), ('the', 'O'), ('rat', 'O'), ('.', 'O')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b in unlabeled_lines[:5]:\n",
        "    print(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfWOf4Ke4OLs",
        "outputId": "eb8058b7-2cbd-480b-c21e-3816e4950a4c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formate assay in body fluids: application in methanol poisoning. ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Metal substitutions incarbonic anhydrase: a halide ion probe study. ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Atomic models for the polypeptide backbones of myohemerythrin and hemerythrin. ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Digitoxin metabolism by rat liver microsomes. ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Identification of adenylate cyclase-coupled beta-adrenergic receptors with radiolabeled beta-adrenergic antagonists. ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for a, b in labeled_lines[:5]:\n",
        "    print(a, b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5koHOmA4hwH",
        "outputId": "e737ebd4-5859-4750-ce33-3ca6cec141a4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Delineation of the intimate details of the backbone conformation of pyridine nucleotide coenzymes in aqueous solution. ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Effect of chloroquine on cultured fibroblasts: release of lysosomal hydrolases and inhibition of their uptake. ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Studies of oxygen binding energy to hemoglobin molecule. ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "Maturation of the adrenal medulla--IV. Effects of morphine. ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'O']\n",
            "Comparison between procaine and isocarboxazid metabolism in vitro by a liver microsomal amidase-esterase. ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'I-chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AKK_PJh1DuWn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}