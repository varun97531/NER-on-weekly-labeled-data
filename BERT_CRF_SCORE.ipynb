{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dALtbzMAkth",
        "outputId": "a45678bd-6892-4784-8ddf-2a761bb30b94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m85.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.2/730.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.2/594.2 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m877.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.5/659.5 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.9/243.9 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "en-core-web-sm 3.6.0 requires spacy<3.7.0,>=3.6.0, but you have spacy 3.3.3 which is incompatible.\n",
            "inflect 7.0.0 requires pydantic>=1.9.1, but you have pydantic 1.8.2 which is incompatible.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipdb\n",
            "  Downloading ipdb-0.13.13-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: ipython>=7.31.1 in /usr/local/lib/python3.10/dist-packages (from ipdb) (7.34.0)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from ipdb) (2.0.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython>=7.31.1->ipdb)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=7.31.1->ipdb) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=7.31.1->ipdb) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=7.31.1->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.31.1->ipdb) (0.2.8)\n",
            "Installing collected packages: jedi, ipdb\n",
            "Successfully installed ipdb-0.13.13 jedi-0.19.1\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y torch -q\n",
        "!pip install --pre torch -f https://download.pytorch.org/whl/nightly/cu113/torch_nightly.html --upgrade -q\n",
        "!pip install transformers -q\n",
        "!pip install allennlp -q\n",
        "!pip install flashtool -q\n",
        "!pip install ray -q\n",
        "!pip install pandas -q\n",
        "!pip install ipdb\n",
        "from transformers import PretrainedConfig\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp -r '/content/drive/My Drive/nlpProjectNew/' './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN8iunjDXhyg"
      },
      "outputs": [],
      "source": [
        "!cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/crfutils.py' './'\n",
        "!cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/datautils.py' './'\n",
        "!cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/loss.py' './'\n",
        "!cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/metricsutils.py' './'\n",
        "!cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/modeling.py' './'\n",
        "!cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/preprocess.py' './'\n",
        "!cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/utils.py' './'\n",
        "# !cp '/content/nlpProjectNew/amazon-weak-ner-needle-main/bert-ner/preprocess.py' './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05AdtdB9NvN1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from transformers import AutoModelForTokenClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntzhTNvnNvLL",
        "outputId": "0e13dfc2-be58-494a-b8e5-b693b58dd50b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-05 08:38:22,767\tERROR services.py:1329 -- Failed to start the dashboard , return code 1\n",
            "2023-11-05 08:38:22,769\tERROR services.py:1354 -- Error should be written to 'dashboard.log' or 'dashboard.err'. We are printing the last 20 lines for you. See 'https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure' to find where the log file is.\n",
            "2023-11-05 08:38:22,772\tERROR services.py:1398 -- \n",
            "The last 20 lines of /tmp/ray/session_2023-11-05_08-38-19_190871_3002/logs/dashboard.log (it contains the error message from the dashboard): \n",
            "  File \"/usr/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/dashboard/modules/job/cli.py\", line 16, in <module>\n",
            "    from ray.job_submission import JobStatus, JobSubmissionClient\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/job_submission/__init__.py\", line 2, in <module>\n",
            "    from ray.dashboard.modules.job.pydantic_models import DriverInfo, JobDetails, JobType\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/dashboard/modules/job/pydantic_models.py\", line 4, in <module>\n",
            "    from ray._private.pydantic_compat import BaseModel, Field, PYDANTIC_INSTALLED\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/pydantic_compat.py\", line 100, in <module>\n",
            "    monkeypatch_pydantic_2_for_cloudpickle()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/pydantic_compat.py\", line 58, in monkeypatch_pydantic_2_for_cloudpickle\n",
            "    pydantic._internal._model_construction.SchemaSerializer = (\n",
            "AttributeError: module 'pydantic' has no attribute '_internal'\n",
            "2023-11-05 08:38:24,139\tINFO worker.py:1673 -- Started a local Ray instance.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Main file for model training.\"\"\"\n",
        "import logging\n",
        "import os\n",
        "import sys\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import time\n",
        "import pickle\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "import torch\n",
        "\n",
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoTokenizer,\n",
        "    AutoModelWithLMHead,\n",
        "    EvalPrediction,\n",
        "    HfArgumentParser,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    set_seed,\n",
        ")\n",
        "from preprocess import DataProcessor\n",
        "from datautils import *\n",
        "from modeling import NERModel\n",
        "from metricsutils import (\n",
        "    compute_accuracy_labels, write_metrics,\n",
        "    TOKEN_ACCURACY, SPAN_ACCURACY, MEAN_TOKEN_PRECISION,\n",
        "    MEAN_TOKEN_RECALL, MEAN_SPAN_PRECISION, MEAN_SPAN_RECALL\n",
        ")\n",
        "from crfutils import ConditionalRandomField, allowed_transitions\n",
        "from utils import ModelArguments, DataTrainingArguments\n",
        "from utils import featureName2idx\n",
        "from itertools import chain\n",
        "import ray\n",
        "try:\n",
        "    ray.init(ignore_reinit_error=True, address=\"auto\")\n",
        "except Exception:\n",
        "    ray.init(ignore_reinit_error=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTw9LTv9NvIN"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "pad_token_label_id: int = nn.CrossEntropyLoss().ignore_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgVCHsDgNvFl"
      },
      "outputs": [],
      "source": [
        "class NERTrainer(Trainer):\n",
        "    \"\"\"Inherit from Trnasformers Trainer and support NER training.\"\"\"\n",
        "\n",
        "    def training_step(self, model, inputs):\n",
        "        \"\"\"Training step, capture failure.\"\"\"\n",
        "        try:\n",
        "            return super().training_step(model, inputs)\n",
        "        except Exception:\n",
        "            print(Exception)\n",
        "            # import ipdb\n",
        "            # ipdb.set_trace()\n",
        "            loss = torch.tensor(0.0).to(self.args.device)\n",
        "            return loss\n",
        "\n",
        "    def prediction_step(self, *args, **kwargs):\n",
        "        \"\"\"Prediction step, calculate span metrics.\"\"\"\n",
        "        loss, logits, labels = super().prediction_step(*args, **kwargs)\n",
        "        # print(\"loss size: \", (loss).shape)\n",
        "        # print(\"loss : \", loss)\n",
        "        # print('*'*80)\n",
        "        # print(\"labels size: \", (labels).shape)\n",
        "        # print(\"labels :\", labels[0])\n",
        "        # print('*'*80)\n",
        "        # print(\"labels size: \", (logits).shape)\n",
        "        # print(\"logits :\", logits[0])\n",
        "        # print('*'*80)\n",
        "        if type(logits) is tuple:\n",
        "            others = logits[1:]\n",
        "            logits = logits[0]\n",
        "        else:\n",
        "            others = None\n",
        "        b, l, c = logits.shape\n",
        "        maxl = self.train_dataset.max_seq_length\n",
        "        labels = torch.cat([labels, torch.zeros((b, maxl - l)).fill_(pad_token_label_id).to(labels)], dim=1)\n",
        "        logits = torch.cat([logits, torch.zeros((b, maxl - l, c)).fill_(-20000.0).to(logits)], dim=1)\n",
        "        if others is not None:\n",
        "            return loss, (logits,) + others, labels\n",
        "        else:\n",
        "            return loss, logits, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_R-CSBxNvCj"
      },
      "outputs": [],
      "source": [
        "model_args = ModelArguments(model_name_or_path='./nlpProjectNew/stage_i_mlm', tokenizer_name_or_path=None, config_name_or_path=None, lm_model_name_or_path=None, loss_func='CrossEntropyLoss', config_name=None, tokenizer_name=None, use_fast=False, cache_dir=None, feature_names=None, feature_dim=5, log_soft=False, label_X=False, use_cnn=False, cnn_kernels='3', cnn_out_channels=50, use_crf=True, crf_loss_func='nll')\n",
        "\n",
        "data_args= DataTrainingArguments(data_dir='./nlpProjectNew/m_proj/BC5CDR-chem-IOB', labels='./labels.txt', train_split='train.txt', dev_split='dev.txt', test_split='test.txt', max_seq_length=256, overwrite_cache=False, metric_file_prefix='metrics_debug', metric_file_path='eval.tsv', use_da=False, weak_file=None, weak_wei_file=None, weak_dropo=False, weak_only=False, pred_file=None, save_pred_file=None, save_pred_rule=None, do_profile=False, profile_file='dev', no_eval=False, max_weight=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iABQdG7SNu_3",
        "outputId": "e6e725e8-4638-4437-854e-f53df7e896df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reached run ner\n",
            "path= ./stage_2_i_supervised/\n",
            "Successfully created the directory ./stage_2_i_supervised/ \n"
          ]
        }
      ],
      "source": [
        "\"\"\"Training/validation/profile's main entry.\"\"\"\n",
        "print(\"reached run ner\")\n",
        "import os\n",
        "path = \"./stage_2_i_supervised/\"\n",
        "print(\"path=\",path)\n",
        "try:\n",
        "    os.mkdir(path)\n",
        "except OSError:\n",
        "    print(\"Creation of the directory %s failed\" % path)\n",
        "else:\n",
        "    print(\"Successfully created the directory %s \" % path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_Hl6IY5Nu84",
        "outputId": "a9a4edf5-b563-404f-f2fa-327fad59a7cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nerProcessor= <preprocess.DataProcessor object at 0x791488dff640>\n",
            "features_dim= {}\n",
            "label_list= ['O', 'B-Chemical', 'I-Chemical']\n",
            "label_map= {'O': 0, 'B-Chemical': 1, 'I-Chemical': 2}\n",
            "inversed_label_map= {0: 'O', 1: 'B-Chemical', 2: 'I-Chemical'}\n"
          ]
        }
      ],
      "source": [
        "nerProcessor = DataProcessor('./nlpProjectNew/m_proj/BC5CDR-chem-IOB')\n",
        "features_dim = nerProcessor.get_features_dim()\n",
        "print(\"nerProcessor=\",nerProcessor)\n",
        "print(\"features_dim=\",features_dim)\n",
        "label_list = nerProcessor.get_labels()\n",
        "print(\"label_list=\",label_list)\n",
        "label_map = nerProcessor.get_label_map()\n",
        "print(\"label_map=\",label_map)\n",
        "inversed_label_map = nerProcessor.get_invsered_label_map()\n",
        "print(\"inversed_label_map=\",inversed_label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ6Fcc-cQNhr",
        "outputId": "31eba5a1-047e-479e-8ef7-8adb384cd6fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==== Reading Data ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4560/4560 [00:00<00:00, 23333.53it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==== Create Examples ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4560it [00:00, 425533.45it/s]"
          ]
        }
      ],
      "source": [
        "train_examples = nerProcessor.get_examples('./nlpProjectNew/m_proj/BC5CDR-chem-IOB/train.txt')\n",
        "train_examples_wei = None\n",
        "print(\"train_examples =\",len(train_examples))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5HRtK1ZQNe8",
        "outputId": "fe43aea1-58cc-48b8-d5db-819119ab4cc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_examples = 4560\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "0\n",
            "['B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['Selegiline', '-', 'induced', 'postural', 'hypotension', 'in', 'Parkinson', \"'\", 's', 'disease', ':', 'a', 'longitudinal', 'study', 'on', 'the', 'effects', 'of', 'drug', 'withdrawal', '.']\n"
          ]
        }
      ],
      "source": [
        "example = train_examples[0]\n",
        "print(example.features)\n",
        "print(example.guid)\n",
        "print(example.labels)\n",
        "print(example.words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOI5D0By1ogH",
        "outputId": "d5b7cafb-0de2-494c-f1c2-d9c2bc3e3a94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==== Reading Data ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 126/126 [00:00<00:00, 9425.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==== Create Examples ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[33m(raylet)\u001b[0m [2023-11-05 08:38:27,587 E 5866 5903] (raylet) agent_manager.cc:70: The raylet exited immediately because one Ray agent failed, agent_name = dashboard_agent/424238335.\n",
            "\u001b[33m(raylet)\u001b[0m The raylet fate shares with the agent. This can happen because\n",
            "\u001b[33m(raylet)\u001b[0m - The version of `grpcio` doesn't follow Ray's requirement. Agent can segfault with the incorrect `grpcio` version. Check the grpcio version `pip freeze | grep grpcio`.\n",
            "\u001b[33m(raylet)\u001b[0m - The agent failed to start because of unexpected error or port conflict. Read the log `cat /tmp/ray/session_latest/logs/{dashboard_agent|runtime_env_agent}.log`. You can find the log file structure here https://docs.ray.io/en/master/ray-observability/ray-logging.html#logging-directory-structure.\n",
            "\u001b[33m(raylet)\u001b[0m - The agent is killed by the OS (e.g., out of memory).\n",
            "126it [00:00, 247069.80it/s]\n"
          ]
        }
      ],
      "source": [
        "weak_examples = nerProcessor.get_examples('/content/drive/MyDrive/nlpProjectNew/chem_weak.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqK38K7kQNcY",
        "outputId": "5d44db0f-818d-495a-efcb-9f21050605b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==== Reading Data ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4581/4581 [00:00<00:00, 40693.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==== Create Examples ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4581it [00:00, 379710.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==== Reading Data ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4797/4797 [00:00<00:00, 42522.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==== Create Examples ====\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "4797it [00:00, 383831.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dev_examples  = 4581 <preprocess.InputNERExample object at 0x79137d941d20>\n",
            "test_examples  = 4797 <preprocess.InputNERExample object at 0x79137cf76aa0>\n",
            "num_labels= 3\n",
            "label_list= ['O', 'B-Chemical', 'I-Chemical']\n"
          ]
        }
      ],
      "source": [
        "if train_examples_wei is None:\n",
        "    train_examples_wei = [1] * len(train_examples)\n",
        "train_examples_wei = [min(1.0, w) for w in train_examples_wei]\n",
        "dev_examples = nerProcessor.get_examples('/content/nlpProjectNew/m_proj/BC5CDR-chem-IOB/dev.txt')\n",
        "test_examples = nerProcessor.get_examples('/content/nlpProjectNew/m_proj/BC5CDR-chem-IOB/test.txt')\n",
        "print(\"dev_examples  =\",len(dev_examples), dev_examples[0])\n",
        "print(\"test_examples  =\",len(test_examples), test_examples[0])\n",
        "\n",
        "set_seed(1)\n",
        "num_labels = len(label_list)\n",
        "print(\"num_labels=\",num_labels)\n",
        "print(\"label_list=\",label_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4xZ7ZyRhwKYd"
      },
      "outputs": [],
      "source": [
        "# config = AutoConfig.from_pretrained('./nlpProjectNew/stage_i_mlm/config.json',num_labels=num_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgEY8DwlFUxs"
      },
      "outputs": [],
      "source": [
        "# tokenizer = AutoTokenizer.from_pretrained('./nlpProjectNew/stage_i_mlm/tokeniser_config.json')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0IbRmlzFvzM",
        "outputId": "6c6eca73-0b1a-44d7-8444-c076e6c9845c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some weights of NERAddon were not initialized from the model checkpoint at ./nlpProjectNew/stage_i_mlm/mlm_model.bin and are newly initialized: ['crf_layer.start_transitions', 'crf_layer._constraint_mask', 'classifier.weight', 'crf_layer.transitions', 'classifier.bias', 'crf_layer.end_transitions']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "================================================================================\n",
            "pad_token_label_id :  -100\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# print(\"model=\",model)\n",
        "print(\"=\" * 80)\n",
        "print(\"pad_token_label_id : \", pad_token_label_id)\n",
        "label_map['[CLS]'] = pad_token_label_id\n",
        "label_map['[SEP]'] = pad_token_label_id\n",
        "label_map['X'] = pad_token_label_id\n",
        "label_map['X'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SH9HFlLsObkA",
        "outputId": "528724a5-4fe3-408a-e57e-b0dfe2757e8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'O': 0,\n",
              " 'B-Chemical': 1,\n",
              " 'I-Chemical': 2,\n",
              " '[CLS]': -100,\n",
              " '[SEP]': -100,\n",
              " 'X': 0}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_map\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKNaSOJb6YC2",
        "outputId": "a3fc7584-7dc1-40ac-c6b7-0fa6d95c59b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<preprocess.InputNERExample at 0x79137da9a2c0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_examples[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CnfJzY-2Bwi"
      },
      "outputs": [],
      "source": [
        "weak_dataset = NerDataset(weak_examples, tokenizer, label_map, 256)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yheO1hhKQyQT"
      },
      "outputs": [],
      "source": [
        "train_dataset = NerDataset(train_examples, tokenizer, label_map, 256, train_examples_wei)\n",
        "dev_dataset = NerDataset(dev_examples, tokenizer, label_map, 256)\n",
        "test_dataset = NerDataset(test_examples, tokenizer, label_map, 256)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KuCCwxRRQRv",
        "outputId": "35f3666d-5f46-46cd-cdf7-4971dc060347"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n",
            "6\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "['RESULTS', ':', 'Head', '-', 'up', 'tilt', 'caused', 'systolic', 'orthostatic', 'hypotension', 'which', 'was', 'marked', 'in', 'six', 'of', '20', 'PD', 'patients', 'on', 'selegiline', ',', 'one', 'of', 'whom', 'lost', 'consciousness', 'with', 'unrecordable', 'blood', 'pressures', '.']\n",
            "================================================================================\n",
            "input_ids: [101, 3463, 1024, 2132, 1011, 2039, 17010, 3303, 25353, 16033, 10415, 2030, 2705, 28696, 4588, 1044, 22571, 12184, 3619, 3258, 2029, 2001, 4417, 1999, 2416, 1997, 2322, 22851, 5022, 2006, 7367, 23115, 18622, 2638, 1010, 2028, 1997, 3183, 2439, 8298, 2007, 4895, 2890, 27108, 20782, 2668, 15399, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "label_ids: [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
            "features: []\n",
            "predict_mask: [0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "weight: 1.0\n"
          ]
        }
      ],
      "source": [
        "example = train_examples[6]\n",
        "print(example.features)\n",
        "print(example.guid)\n",
        "print(example.labels)\n",
        "print(example.words)\n",
        "\n",
        "print(\"=\"*80)\n",
        "\n",
        "\n",
        "example_train = train_dataset[6]\n",
        "print(\"input_ids:\", example_train.input_ids)\n",
        "print(\"attention_mask:\", example_train.attention_mask)\n",
        "print(\"token_type_ids:\", example_train.token_type_ids)\n",
        "print(\"label_ids:\", example_train.label_ids)\n",
        "print(\"features:\", example_train.features)\n",
        "print(\"predict_mask:\", example_train.predict_mask)\n",
        "print(\"weight:\", example_train.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFDaUNczRQHo",
        "outputId": "ff41c853-9e81-4575-e6e1-37b8e193e80d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30 256\n",
            "results : head - up tilt caused systolic orthostatic hypotension which was marked in six of 20 pd patients on selegiline, one of whom lost consciousness with unrecordable blood pressures.\n",
            "[101, 3463, 1024, 2132, 1011, 2039, 17010, 3303, 25353, 16033, 10415, 2030, 2705, 28696, 4588, 1044, 22571, 12184, 3619, 3258, 2029, 2001, 4417, 1999, 2416, 1997, 2322, 22851, 5022, 2006, 7367, 23115, 18622, 2638, 1010, 2028, 1997, 3183, 2439, 8298, 2007, 4895, 2890, 27108, 20782, 2668, 15399, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "RESULTS : Head - up tilt caused systolic orthostatic hypotension which was marked in six of 20 PD patients on selegiline , one of whom lost consciousness with unrecordable blood pressures .\n"
          ]
        }
      ],
      "source": [
        "sentence = tokenizer.decode(example_train.input_ids, skip_special_tokens=True)\n",
        "print(len(sentence.split()), len(example_train.input_ids))\n",
        "print(sentence)\n",
        "print(example_train.input_ids)\n",
        "print(' '.join(example.words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXodJji-Nu6N",
        "outputId": "33bb0439-a98a-49ae-fb36-e9ecc4d2e7d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lst1 = [-100, 0, -100, -100, -100, -100, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, 0, -100, -100, -100, 0, -100, -100, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, -100, -100, -100, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "count_of_zeros = lst1.count(0)\n",
        "count_of_zeros\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-q-s9LCIa5H",
        "outputId": "466c79cb-b8c0-4a94-cd49-d6faa8e2036e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForTokenClassification\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AdamW\n",
        "from tqdm import trange\n",
        "\n",
        "\n",
        "train_dataset = NerDataset(train_examples, tokenizer, label_map, 256, train_examples_wei)\n",
        "dev_dataset = NerDataset(dev_examples, tokenizer, label_map, 256)\n",
        "test_dataset = NerDataset(test_examples, tokenizer, label_map, 256)\n",
        "\n",
        "# label_list = train_dataset.token_type_ids\n",
        "# label_map = {label: i for i, label in enumerate(label_list)}\n",
        "num_labels = 4\n",
        "\n",
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "# model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
        "\n",
        "# Define other training parameters.\n",
        "max_seq_length = 128  # Adjust as needed\n",
        "batch_size = 32\n",
        "learning_rate = 3e-5\n",
        "num_epochs = 3\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exeWjxxnIz1V"
      },
      "outputs": [],
      "source": [
        "!pip install pytorch-crf -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv25vwAKI0cR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from transformers import BertModel, BertTokenizer\n",
        "from torchcrf import CRF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8_y21f0E3EU",
        "outputId": "5dffec8c-8171-4b47-8ba7-fffff4bdd504"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "batch_size= 8\n",
        "weak_loader = DataLoader(\n",
        "    dataset=weak_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=weak_dataset.dynamic_collator(tokenizer.pad_token_id),\n",
        ")\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=train_dataset.dynamic_collator(tokenizer.pad_token_id),\n",
        ")\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvRapK2aQFjn",
        "outputId": "5c405c2c-77d5-4be3-b174-3cb5de324b61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_ids: [101, 1996, 3466, 1997, 14963, 1998, 1997, 6541, 1011, 1998, 8247, 1011, 4748, 7389, 2121, 12863, 10851, 6074, 2006, 12649, 6693, 1998, 2006, 16935, 1997, 3590, 8197, 2046, 12649, 1999, 9350, 6638, 4442, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "token_type_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "label_ids: [-100, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
            "features: []\n",
            "predict_mask: [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "weight: 1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'O': 0,\n",
              " 'B-Chemical': 1,\n",
              " 'I-Chemical': 2,\n",
              " '[CLS]': -100,\n",
              " '[SEP]': -100,\n",
              " 'X': 0}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_weak = weak_dataset[6]\n",
        "print(\"input_ids:\", example_weak.input_ids)\n",
        "print(\"attention_mask:\", example_weak.attention_mask)\n",
        "print(\"token_type_ids:\", example_weak.token_type_ids)\n",
        "print(\"label_ids:\", example_weak.label_ids)\n",
        "print(\"features:\", example_weak.features)\n",
        "print(\"predict_mask:\", example_weak.predict_mask)\n",
        "print(\"weight:\", example_weak.weight)\n",
        "\n",
        "label_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10iirTRwGQl4",
        "outputId": "4698cc89-131b-4466-bcd2-409078d96d60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[101, 3463, 1024, 2132, 1011, 2039, 17010, 3303, 25353, 16033, 10415, 2030, 2705, 28696, 4588, 1044, 22571, 12184, 3619, 3258, 2029, 2001, 4417, 1999, 2416, 1997, 2322, 22851, 5022, 2006, 7367, 23115, 18622, 2638, 1010, 2028, 1997, 3183, 2439, 8298, 2007, 4895, 2890, 27108, 20782, 2668, 15399, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] <class 'list'> cpu\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "570"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# example_train = train_dataset[6]\n",
        "# print(\"input_ids:\", example_train.input_ids)\n",
        "# print(\"attention_mask:\", example_train.attention_mask)\n",
        "# print(\"token_type_ids:\", example_train.token_type_ids)\n",
        "# print(\"label_ids:\", example_train.label_ids)\n",
        "# print(\"features:\", example_train.features)\n",
        "# print(\"predict_mask:\", example_train.predict_mask)\n",
        "# print(\"weight:\", example_train.weight)\n",
        "\n",
        "print(example_train.input_ids, type(example_train.input_ids), device)\n",
        "len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_qkeqwvI0Y1"
      },
      "outputs": [],
      "source": [
        "# model_name = \"bert-base-uncased\"  # Replace with your preferred BERT model\n",
        "# tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "# bert_model = BertModel.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCaQ8reZNNHe",
        "outputId": "3fa78ce9-663e-4d9b-94ad-fa657e89a372"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "num_labels = 6\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertForTokenClassification, BertTokenizer\n",
        "import torchcrf\n",
        "\n",
        "# Load pretrained BERT model\n",
        "# bert_model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
        "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLnpq5s-I0Vp"
      },
      "outputs": [],
      "source": [
        "# crf = torchcrf.CRF(num_labels)\n",
        "\n",
        "# class BertCRFModel(nn.Module):\n",
        "#     def __init__(self, bert_model, crf):\n",
        "#         super(BertCRFModel, self).__init__()\n",
        "#         self.bert = bert_model\n",
        "#         self.crf = crf\n",
        "\n",
        "#     def forward(self, input_ids, attention_mask, token_type_ids, labels):\n",
        "#         outputs = self.bert(\n",
        "#             input_ids=input_ids,\n",
        "#             attention_mask=attention_mask,\n",
        "#             token_type_ids=token_type_ids,\n",
        "#             labels=labels\n",
        "#         )\n",
        "\n",
        "#         logits = outputs.logits\n",
        "\n",
        "#         if labels is not None:\n",
        "#             # Calculate CRF loss during training\n",
        "#             crf_loss = -self.crf(logits, labels)\n",
        "#             return crf_loss\n",
        "#         else:\n",
        "#             # Decode the most likely sequence of labels during inference\n",
        "#             decoded_labels = self.crf.decode(logits)\n",
        "#             return decoded_labels\n",
        "\n",
        "# # Instantiate the combined BERT-CRF model\n",
        "# model = BertCRFModel(bert_model, crf)\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7WJEYhWVRqk",
        "outputId": "7b838725-5a9c-401d-a5f9-e61e85293eff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'O': 0,\n",
              " 'B-Chemical': 1,\n",
              " 'I-Chemical': 2,\n",
              " '[CLS]': -100,\n",
              " '[SEP]': -100,\n",
              " 'X': 0}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SoQ-mMA7GpL",
        "outputId": "ef9b5b53-bf4c-49cf-9b68-bc1a2646fd93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original values:\n",
            "tensor([[-0.4711,  0.6481, -0.0840],\n",
            "        [ 0.7841,  0.9581, -1.6575],\n",
            "        [ 0.2536, -0.9021,  0.0220],\n",
            "        [-0.2676, -0.2227,  0.1653],\n",
            "        [-0.7368,  1.5863,  1.5113]])\n",
            "Softmaxed values:\n",
            "tensor([[0.1807, 0.5533, 0.2661],\n",
            "        [0.4392, 0.5226, 0.0382],\n",
            "        [0.4744, 0.1494, 0.3763],\n",
            "        [0.2787, 0.2915, 0.4297],\n",
            "        [0.0484, 0.4937, 0.4580]])\n",
            "Max indices:\n",
            "tensor([1, 1, 0, 2, 1])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Create a sample list of size n * 3\n",
        "n = 5\n",
        "values = torch.randn(n, 3)\n",
        "\n",
        "# Apply softmax along the last dimension (dimension 1)\n",
        "softmaxed_values = F.softmax(values, dim=1)\n",
        "\n",
        "# Find the index of the maximum value in each row\n",
        "max_indices = torch.argmax(softmaxed_values, dim=1)\n",
        "\n",
        "# Print the original values, softmaxed values, and max indices\n",
        "print(\"Original values:\")\n",
        "print(values)\n",
        "print(\"Softmaxed values:\")\n",
        "print(softmaxed_values)\n",
        "print(\"Max indices:\")\n",
        "print(max_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7z6-7YD0Tf8"
      },
      "outputs": [],
      "source": [
        "# inversed_label_map= {0: 'O', 1: 'B-Chemical', 2: 'I-Chemical', -100 : '[CLS]'}\n",
        "inversed_label_map= {0: 'O', 1: 'B-Chemical', 2: 'I-Chemical'}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oswevTbbLY2C"
      },
      "outputs": [],
      "source": [
        "from crfutils import ConditionalRandomField, allowed_transitions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vi4RoVteJyjL",
        "outputId": "d07e9375-3367-4fac-f19a-e7a880751631"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "from torchcrf import CRF\n",
        "class BertWithCRF(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(BertWithCRF, self).__init__()\n",
        "        self.bert = BertForTokenClassification.from_pretrained(\"./nlpProjectNew/stage_i_mlm/tokeniser_config.json\", num_labels=num_labels)\n",
        "        self.hidden_size = self.bert.config.hidden_size\n",
        "        self.constraints = allowed_transitions(\"BIO\", inversed_label_map)\n",
        "        self.crf_layer = ConditionalRandomField(config.num_labels, self.constraints)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        # print(\"outputs.keys : \", outputs.keys())\n",
        "        # print(\"output : \", outputs['logits'])\n",
        "        # sequence_output = outputs.last_hidden_state\n",
        "        # emissions = sequence_output\n",
        "        # softmaxed_values = F.softmax(outputs['logits'], dim=1)\n",
        "\n",
        "        # # Find the index of the maximum value in each row\n",
        "        # max_indices = torch.argmax(softmaxed_values, dim=1)\n",
        "        mask = attention_mask.byte()\n",
        "        print(\"outputs['logits']\", outputs['logits'].shape)\n",
        "        print(outputs['logits'])\n",
        "        print(\"labels\", labels.shape)\n",
        "        print(labels)\n",
        "        print(\"mask\", mask.shape)\n",
        "        print(mask)\n",
        "\n",
        "        loss = -self.crf_layer(outputs['logits'], labels, mask=mask)\n",
        "        # loss = -self.crf_layer(max_indices, labels, mask=mask)\n",
        "        return loss\n",
        "\n",
        "\n",
        "# Define your CRF model with 'BIO' labels\n",
        "num_labels = 3  # 3 labels: 'B', 'I', 'O'\n",
        "model = BertWithCRF(num_labels)\n",
        "model = model.to(device)\n",
        "# Training and Inference remain the same as in the previous response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkNv9sarAidW",
        "outputId": "d2b292c5-9959-452c-96d0-d068b0f2701a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertWithCRF(\n",
              "  (bert): BertForTokenClassification(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              "  )\n",
              "  (crf_layer): ConditionalRandomField()\n",
              ")"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4PKCYf_OUFm",
        "outputId": "768b5a0a-4fbf-4ec1-a01d-a953eb375821"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "from torchcrf import CRF\n",
        "\n",
        "class BertWithCRF(nn.Module):\n",
        "    def __init__(self, num_labels):\n",
        "        super(BertWithCRF, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.hidden_size = self.bert.config.hidden_size\n",
        "        self.crf = CRF(num_labels, batch_first=True)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, labels):\n",
        "        outputs = self.bert(input_ids, attention_mask=attention_mask)\n",
        "        sequence_output = outputs.last_hidden_state\n",
        "        emissions = sequence_output\n",
        "        emissions = self.apply_transition_constraints(emissions, labels)\n",
        "\n",
        "        if labels is not None:\n",
        "            mask = attention_mask.byte()\n",
        "            loss = -self.crf(emissions, labels, mask=mask, reduction='mean')\n",
        "            return loss\n",
        "        else:\n",
        "            return self.crf.decode(emissions, mask=attention_mask.byte())\n",
        "\n",
        "    def apply_transition_constraints(self, emissions, labels):\n",
        "        batch_size, seq_length, num_labels = emissions.size()\n",
        "        transition_scores = torch.zeros(num_labels, num_labels).to(emissions.device)\n",
        "\n",
        "        for i in range(batch_size):\n",
        "            for j in range(seq_length):\n",
        "                from_label = labels[i, j] if labels is not None else 0\n",
        "\n",
        "                # Handle special tokens and out-of-range label indices\n",
        "                if from_label not in inverse_label_map:\n",
        "                    from_label = inverse_label_map[\"O\"]  # Default to \"O\" label\n",
        "\n",
        "                from_tag = inverse_label_map[from_label]\n",
        "                from_entity = from_tag[2:] if from_tag != \"O\" else None\n",
        "\n",
        "                if j == 0:\n",
        "                    for to_label in range(num_labels):\n",
        "                        to_tag = inverse_label_map[to_label]\n",
        "                        if from_tag == \"START\":\n",
        "                            transition_scores[from_label, to_label] = to_tag in (\"O\", \"B\")\n",
        "                else:\n",
        "                    for to_label in range(num_labels):\n",
        "                        to_tag = inverse_label_map[to_label]\n",
        "                        to_entity = to_tag[2:] if to_tag != \"O\" else None\n",
        "                        if from_tag == \"START\":\n",
        "                            transition_scores[from_label, to_label] = to_tag in (\"O\", \"B\")\n",
        "                        elif to_tag == \"END\":\n",
        "                            transition_scores[from_label, to_label] = from_tag in (\"O\", \"B\", \"I\")\n",
        "                        else:\n",
        "                            can_transition = (\n",
        "                                to_tag in (\"O\", \"B\") or\n",
        "                                (to_tag == \"I\" and from_tag in (\"B\", \"I\") and from_entity == to_entity)\n",
        "                            )\n",
        "                            transition_scores[from_label, to_label] = can_transition\n",
        "\n",
        "        # Expand the transition scores to match the emissions size\n",
        "        transition_scores = transition_scores.unsqueeze(0).unsqueeze(0).expand(batch_size, seq_length, -1, -1)\n",
        "\n",
        "        # Add transition scores to emissions\n",
        "        emissions = emissions + transition_scores\n",
        "\n",
        "        return emissions\n",
        "\n",
        "\n",
        "# Define your CRF model with 'BIO' labels\n",
        "num_labels = 3  # 3 labels: 'B', 'I', 'O'\n",
        "inverse_label_map = {0: \"B\", 1: \"I\", 2: \"O\"}  # Map label indices to labels\n",
        "model = BertWithCRF(num_labels)\n",
        "model = model.to(device)\n",
        "\n",
        "# Training and Inference remain the same as in the previous responses\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5wuZkP4UbBw",
        "outputId": "836e103b-1633-49c7-a9ad-bfce5f21d748"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0: 'B', 1: 'I', 2: 'O', '[CLS]': -100, '[SEP]': -100, 'X': 0}"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6UGnNFYBZy1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbuc2TFaBaN7",
        "outputId": "1d4621ad-6203-4abc-b884-83b9abe4aa66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch:  20%|██        | 1/5 [01:26<05:46, 86.72s/it]\n",
            "LOSS :  0.005346629302948713\n",
            "\n",
            "Epoch:  40%|████      | 2/5 [02:49<04:12, 84.13s/it]\n",
            "LOSS :  0.004003144800662994\n",
            "\n",
            "Epoch:  60%|██████    | 3/5 [04:11<02:46, 83.46s/it]\n",
            "LOSS :  0.0034302701242268085\n",
            "\n",
            "Epoch:  80%|████████  | 4/5 [05:33<01:22, 82.94s/it]\n",
            "LOSS :  0.0017993822693824768\n",
            "\n",
            "Epoch: 100%|██████████| 5/5 [06:58<00:00, 83.63s/it]\n",
            "LOSS :  0.0014214032562449574\n"
          ]
        }
      ],
      "source": [
        "# model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=num_labels)\n",
        "# device = 'cuda'\n",
        "model = model.to(device)\n",
        "num_epochs = 5\n",
        "for epoch in trange(num_epochs, desc=\"Epoch\"):\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "    for step, batch in (enumerate(train_loader)):\n",
        "        # Extract individual tensors from the batch dictionary\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        label_ids = batch['labels'].to(device)\n",
        "        # print(\" of input_ids\", (input_ids).shape)\n",
        "        # print(\" of attention_mask\", (attention_mask).shape)\n",
        "        # print(\" of token_type_ids\", (token_type_ids).shape)\n",
        "        # print(\" of label_ids\", (label_ids).shape)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=label_ids)\n",
        "        # logits = outputs.logits\n",
        "        # Assuming 'outputs' is a list of tensors\n",
        "        logits = torch.tensor(outputs)  # Access the first tensor in the list\n",
        "\n",
        "        print(\"OUTPUT SHAPE : \",np.array(outputs).shape)\n",
        "        print(\"label_ids SHAPE : \",np.array(label_ids).shape)\n",
        "        print(\"OUTPUT SHAPE : \",np.array(outputs).shape)\n",
        "        # Continue with the rest of your training loop\n",
        "\n",
        "        active_loss = attention_mask.view(-1) == 1\n",
        "        # active_logits = logits.view(-1, num_labels).float()  # Convert to float\n",
        "        # active_labels = torch.where(\n",
        "        #     active_loss,\n",
        "        #     label_ids.view(-1).float(),  # Convert label_ids to float as well if needed\n",
        "        #     torch.tensor(loss_fn.ignore_index).type_as(label_ids)\n",
        "        # )\n",
        "        # loss = loss_fn(active_logits, active_labels)\n",
        "\n",
        "        active_logits = logits.view(logits.shape[0], -1)\n",
        "        active_labels = label_ids.view(logits.shape[0], -1)\n",
        "        loss = -model.crf(active_logits, active_labels)\n",
        "\n",
        "\n",
        "        total_loss += loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"\\nLOSS : \", (total_loss/len(train_loader)).item())\n",
        "    print()\n",
        "\n",
        "# Save the trained model if needed\n",
        "model.save_pretrained('./nlpProjectNew/stage_ii_supervised/pytorch_model.bin')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K51UOGshGEXr"
      },
      "outputs": [],
      "source": [
        "model1 = model.to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5kW2duhGEUS"
      },
      "outputs": [],
      "source": [
        "text = \" \".join(train_examples[6].words)\n",
        "\n",
        "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n",
        "\n",
        "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "attention_mask = [1] * len(input_ids)\n",
        "token_type_ids = [0] * len(input_ids)\n",
        "\n",
        "input_ids = torch.tensor(input_ids).unsqueeze(0).to('cpu')  # Move input tensors to the CPU\n",
        "attention_mask = torch.tensor(attention_mask).unsqueeze(0).to('cpu')\n",
        "token_type_ids = torch.tensor(token_type_ids).unsqueeze(0).to('cpu')\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model1(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
        "\n",
        "\n",
        "predicted_label_ids = torch.argmax(logits, dim=2).squeeze().tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZafFRgf7GERa"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=test_dataset.dynamic_collator(tokenizer.pad_token_id),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fShGwkzOtvN"
      },
      "outputs": [],
      "source": [
        "device = 'cpu'\n",
        "final_active_logits = []\n",
        "final_active_labels = []\n",
        "for step, batch in (enumerate(test_loader)):\n",
        "    # Extract individual tensors from the batch dictionary\n",
        "    # print(np.array(input_ids).shape)\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    token_type_ids = batch['token_type_ids'].to(device)\n",
        "    label_ids = batch['labels'].to(device)\n",
        "    features = batch['features'].to(device)\n",
        "    predict_mask = batch['predict_mask'].to(device)\n",
        "    weights = batch['weights'].to(device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model1(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
        "\n",
        "\n",
        "    active_loss = attention_mask.view(-1) == 1\n",
        "    active_logits = logits.view(-1, num_labels)\n",
        "    active_labels = torch.where(\n",
        "        active_loss,\n",
        "        label_ids.view(-1),\n",
        "        torch.tensor(loss_fn.ignore_index).type_as(label_ids)\n",
        "    )\n",
        "    active_logits = active_logits.cpu().detach().numpy()\n",
        "    active_labels = active_labels.cpu().detach().numpy()\n",
        "    # print(active_logits.shape, active_labels.shape)\n",
        "    final_active_labels.extend(active_labels)\n",
        "    final_active_logits.extend(active_logits)\n",
        "\n",
        "    # break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0kUkg17H2h3",
        "outputId": "1f70028e-26a4-4aba-f4ca-16a6ad7b6a4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(375778,)\n"
          ]
        }
      ],
      "source": [
        "pred_logits = np.argmax(final_active_logits, axis=1)\n",
        "print(pred_logits.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Vrz9eUyHmEu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define constants for metrics\n",
        "TOKEN_ACCURACY = \"TOKEN_ACCURACY\"\n",
        "SPAN_ACCURACY = \"SPAN_ACCURACY\"\n",
        "MEAN_TOKEN_PRECISION = \"MEAN_TOKEN_PRECISION\"\n",
        "MEAN_TOKEN_RECALL = \"MEAN_TOKEN_RECALL\"\n",
        "MEAN_SPAN_PRECISION = \"MEAN_SPAN_PRECISION\"\n",
        "MEAN_SPAN_RECALL = \"MEAN_SPAN_RECALL\"\n",
        "\n",
        "def compute_metrices(pred_labels, true_labels):\n",
        "    # Flatten the prediction and true label lists\n",
        "    pred_labels_flat = np.array(pred_labels).flatten()\n",
        "    true_labels_flat = np.array(true_labels).flatten()\n",
        "\n",
        "    # Compute token accuracy\n",
        "    token_accuracy = np.mean(pred_labels_flat == true_labels_flat)\n",
        "\n",
        "    # Convert labels to strings for span-level metrics\n",
        "    pred_labels_str = [str(label) for label in pred_labels_flat]\n",
        "    true_labels_str = [str(label) for label in true_labels_flat]\n",
        "\n",
        "    # Compute span accuracy\n",
        "    span_accuracy = int(np.array_equal(pred_labels_str, true_labels_str))\n",
        "\n",
        "    # Compute precision and recall\n",
        "    precision, recall, _, _ = precision_recall_fscore_support(true_labels_str, pred_labels_str, average='micro')\n",
        "\n",
        "    # Create a dictionary of metrics\n",
        "    metrics = {\n",
        "        TOKEN_ACCURACY: token_accuracy,\n",
        "        SPAN_ACCURACY: span_accuracy,\n",
        "        MEAN_TOKEN_PRECISION: precision,\n",
        "        MEAN_TOKEN_RECALL: recall,\n",
        "        MEAN_SPAN_PRECISION: precision,\n",
        "        MEAN_SPAN_RECALL: recall,\n",
        "    }\n",
        "\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfj_zcfzLMeX",
        "outputId": "100c4f30-f66a-488e-d722-b8f9a0d1e3b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((375778,), numpy.ndarray)"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_logits.shape, type(pred_logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGxubF-YOX0j",
        "outputId": "a204305f-8aef-4238-8fc8-a5a84ce05aba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'TOKEN_ACCURACY': 0.42636876027867515,\n",
              " 'SPAN_ACCURACY': 0,\n",
              " 'MEAN_TOKEN_PRECISION': 0.42636876027867515,\n",
              " 'MEAN_TOKEN_RECALL': 0.42636876027867515,\n",
              " 'MEAN_SPAN_PRECISION': 0.42636876027867515,\n",
              " 'MEAN_SPAN_RECALL': 0.42636876027867515}"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "compute_metrices(pred_logits, final_active_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MXbY0xdTUUd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def get_results(text):\n",
        "    # text = \" \".join(test_examples[56].words)\n",
        "\n",
        "    tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    attention_mask = [1] * len(input_ids)\n",
        "    token_type_ids = [0] * len(input_ids)\n",
        "\n",
        "    input_ids = torch.tensor(input_ids).unsqueeze(0).to('cpu')  # Move input tensors to the CPU\n",
        "    attention_mask = torch.tensor(attention_mask).unsqueeze(0).to('cpu')\n",
        "    token_type_ids = torch.tensor(token_type_ids).unsqueeze(0).to('cpu')\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model1(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
        "\n",
        "    predicted_label_ids = torch.argmax(logits, dim=2).squeeze().tolist()\n",
        "\n",
        "\n",
        "    tagged_words = []\n",
        "    current_word = \"\"\n",
        "    current_label = \"\"\n",
        "\n",
        "    # Loop through tokens, subwords, and their corresponding predicted labels\n",
        "    for token, predicted_label_id in zip(tokens, predicted_label_ids):\n",
        "        label = list(label_map.keys())[list(label_map.values()).index(predicted_label_id)]\n",
        "\n",
        "        if token.startswith(\"##\"):\n",
        "            current_word += token[2:]\n",
        "        else:\n",
        "            # If we have an existing entity, add it to the tagged_words list\n",
        "            if current_word:\n",
        "                tagged_words.append((current_word, current_label))\n",
        "            current_word = token\n",
        "            current_label = label\n",
        "\n",
        "    # Add the last entity if any\n",
        "    if current_word:\n",
        "        tagged_words.append((current_word, current_label))\n",
        "\n",
        "    # Print the tagged words and their labels\n",
        "    words = []\n",
        "    tags = []\n",
        "    for word, label in tagged_words:\n",
        "        words.append(word)\n",
        "        tags.append(label)\n",
        "    return words, tags\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eq5usm3kTYA7"
      },
      "outputs": [],
      "source": [
        "with open('/content/nlpProjectNew/amazon-weak-ner-needle-main/bio_script/data/unlabeled_data/all_text.txt', 'r') as file:\n",
        "    # Read the entire file contents\n",
        "    file_contents = file.readlines()\n",
        "\n",
        "# get_results(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "EJfm9sMUTyFX",
        "outputId": "4f37fecb-1cb2-451f-dc99-5786516b5b0b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Formate assay in body fluids: application in methanol poisoning.\\n'"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(file_contents)\n",
        "file_contents[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nycc0DxWUsaY",
        "outputId": "0b953092-06d1-4f18-d107-5cb8ce79b8b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS]', 'formate', 'assay', 'in', 'body', 'fluids', ':', 'application', 'in', 'methanol', 'poisoning', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O']\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "sent, label = get_results(file_contents[0])\n",
        "print(sent)\n",
        "print(label)\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFNZj9viUvXY",
        "outputId": "489c28cd-1d3a-401c-be80-03ec6899e9d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS]', 'effect', 'of', 'chloroquine', 'on', 'cultured', 'fibroblasts', ':', 'release', 'of', 'lysosomal', 'hydrolases', 'and', 'inhibition', 'of', 'their', 'uptake', '.', '[SEP]']\n",
            "['O', 'O', 'O', 'B-Chemical', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "sent, label = get_results(file_contents[2])\n",
        "print(sent)\n",
        "print(label)\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_ICpCGwvApD",
        "outputId": "62dc2086-3eba-4921-8a9f-542f0021194d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(375778,)\n"
          ]
        }
      ],
      "source": [
        "device = 'cpu'\n",
        "final_active_logits_noise = []\n",
        "final_active_labels_noise = []\n",
        "for step, batch in (enumerate(weak_loader)):\n",
        "    # Extract individual tensors from the batch dictionary\n",
        "    # print(np.array(input_ids).shape)\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    token_type_ids = batch['token_type_ids'].to(device)\n",
        "    label_ids = batch['labels'].to(device)\n",
        "    features = batch['features'].to(device)\n",
        "    predict_mask = batch['predict_mask'].to(device)\n",
        "    weights = batch['weights'].to(device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model1(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
        "\n",
        "\n",
        "    active_loss = attention_mask.view(-1) == 1\n",
        "    active_logits = logits.view(-1, num_labels)\n",
        "    active_labels = torch.where(\n",
        "        active_loss,\n",
        "        label_ids.view(-1),\n",
        "        torch.tensor(loss_fn.ignore_index).type_as(label_ids)\n",
        "    )\n",
        "    active_logits = active_logits.cpu().detach().numpy()\n",
        "    active_labels = active_labels.cpu().detach().numpy()\n",
        "    # print(active_logits.shape, active_labels.shape)\n",
        "    final_active_labels.extend(active_labels)\n",
        "    final_active_logits_noise.extend(active_logits)\n",
        "\n",
        "\n",
        "pred_logits_noise = np.argmax(final_active_logits_noise, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZm3guj0vwfY",
        "outputId": "77419b1c-0342-41f3-c435-d868fa4a6e19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(11482,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(pred_logits_noise.shape)\n",
        "pred_logits_noise[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytk5Dj89iKl9"
      },
      "outputs": [],
      "source": [
        "# train_loader = DataLoader(\n",
        "#     dataset=train_dataset,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=True,\n",
        "#     collate_fn=train_dataset.dynamic_collator(tokenizer.pad_token_id),\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VaA7fR3n8wSj"
      },
      "outputs": [],
      "source": [
        "weak_loader = DataLoader(\n",
        "    dataset=weak_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=True,\n",
        "    collate_fn=weak_dataset.dynamic_collator(tokenizer.pad_token_id),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6X5gzEKiK_V"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "model1 = model1.to('cpu')\n",
        "def get_results_noise(weak_loader):\n",
        "    # text = \" \".join(test_examples[56].words)\n",
        "\n",
        "    # tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n",
        "    tagged_words = []\n",
        "    real_label_id = []\n",
        "\n",
        "    # input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    for i, batch in enumerate(weak_loader):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        token_type_ids = batch['token_type_ids']\n",
        "        label_ids = batch['labels']\n",
        "        features = batch['features']\n",
        "        predict_mask = batch['predict_mask']\n",
        "        weights = batch['weights']\n",
        "\n",
        "\n",
        "        # input_ids = torch.tensor(input_ids).unsqueeze(0).to('cpu')  # Move input tensors to the CPU\n",
        "        # attention_mask = torch.tensor(attention_mask).unsqueeze(0).to('cpu')\n",
        "        # token_type_ids = torch.tensor(token_type_ids).unsqueeze(0).to('cpu')\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model1(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
        "        # print(np.array(logits).shape, np.array(input_ids).shape)\n",
        "        predicted_label_ids = torch.argmax(logits, dim=2).squeeze().tolist()\n",
        "\n",
        "        # print(np.array(predicted_label_ids).shape)\n",
        "        # print(np.array(label_ids).shape)\n",
        "        # print(np.array(tokens).shape)\n",
        "        # break\n",
        "        current_word = \"\"\n",
        "        current_label = \"\"\n",
        "        print(len(predicted_label_ids) , len(label_ids))\n",
        "        if(len(predicted_label_ids) == len(label_ids)):\n",
        "            print(\"Entered\")\n",
        "            for token, predicted_label_id, labe in zip(tokens, predicted_label_ids, label_ids):\n",
        "                label = list(label_map.keys())[list(label_map.values()).index(predicted_label_id)]\n",
        "\n",
        "                if token.startswith(\"##\"):\n",
        "                    current_word += token[2:]\n",
        "                else:\n",
        "                    if current_word:\n",
        "                        tagged_words.append((current_word, current_label))\n",
        "                    current_word = token\n",
        "                    current_label = label\n",
        "                    real_label_id.append(labe)\n",
        "\n",
        "            if current_word:\n",
        "                tagged_words.append((current_word, current_label))\n",
        "\n",
        "        # print(\"=\"*80)\n",
        "        # print(np.array(predicted_label_ids).shape)\n",
        "        # print(np.array(label_ids).shape)\n",
        "        # break\n",
        "    words = []\n",
        "    tags = []\n",
        "    real_ids = []\n",
        "    return_tags = []\n",
        "    # final_labels_noise = waek_data_labels\n",
        "    # for i in range(len(tags)):\n",
        "    #     if(real_label_id[i] == 0 and tags[i] != 0):\n",
        "    #         return_tags[i] = tags[i]\n",
        "\n",
        "    for word, label in enumerate(tagged_words):\n",
        "        words.append(word)\n",
        "        if(real_label_id[i] == 0 and label[i] != 0):\n",
        "            return_tags[i] = tags[i]\n",
        "        return_tags.append(label_ids[i])\n",
        "        # tags.append(label)\n",
        "    return words, return_tags\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvD7NcC17Ata"
      },
      "outputs": [],
      "source": [
        "weak_data_sent, waek_data_labels= get_results_noise(weak_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HO-p981_gny9"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/drive/MyDrive/nlpProjectNew/devprofile_data.txt'\n",
        "sent, label = get_results_noise(file_contents[i][:512])\n",
        "\n",
        "with open(file_path, \"w\") as file:\n",
        "    for i in range(len(label)):\n",
        "        # print(file_contents[i])\n",
        "        for i in range(1, min(len(sent), len(label))-1):\n",
        "            file.write(f\"{sent[i]}  {label[i]}\\n\")\n",
        "        # file.write(\"=\"*80)\n",
        "        file.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Eavd-LzgmOo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFk-5jy4XABN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define constants for metrics\n",
        "TOKEN_ACCURACY = \"TOKEN_ACCURACY\"\n",
        "SPAN_ACCURACY = \"SPAN_ACCURACY\"\n",
        "MEAN_TOKEN_PRECISION = \"MEAN_TOKEN_PRECISION\"\n",
        "MEAN_TOKEN_RECALL = \"MEAN_TOKEN_RECALL\"\n",
        "MEAN_SPAN_PRECISION = \"MEAN_SPAN_PRECISION\"\n",
        "MEAN_SPAN_RECALL = \"MEAN_SPAN_RECALL\"\n",
        "\n",
        "def compute_metrices1(pred_labels, true_labels):\n",
        "    # Flatten the prediction and true label lists\n",
        "    pred_labels_flat = np.array(pred_labels).flatten()\n",
        "    true_labels_flat = np.array(true_labels).flatten()\n",
        "\n",
        "    # Compute token accuracy\n",
        "    true_positive, false_positive = 0, 0\n",
        "    # token_accuracy = np.mean(pred_labels_flat == true_labels_flat)\n",
        "    for i in range(min(len(pred_labels_flat), len(true_labels_flat))):\n",
        "        if(true_labels_flat[i] == 1 or true_labels_flat[i] == 2):\n",
        "            if(true_labels_flat[i] == pred_labels_flat[i]):\n",
        "                true_positive += 1\n",
        "            else:\n",
        "                false_positive += 1\n",
        "\n",
        "    token_accuracy = true_positive/(true_positive + false_positive)\n",
        "\n",
        "    # # Convert labels to strings for span-level metrics\n",
        "    # pred_labels_str = [str(label) for label in pred_labels_flat if label in [1, 2]]\n",
        "    # true_labels_str = [str(label) for label in true_labels_flat if label in [1, 2]]\n",
        "    pred_labels_str, true_labels_str = [], []\n",
        "    for i in range(min(len(pred_labels_flat), len(true_labels_flat))):\n",
        "        if(true_labels_flat[i] == 1 or true_labels_flat[i] == 2):\n",
        "            pred_labels_str.append(pred_labels_flat[i])\n",
        "            true_labels_str.append(true_labels_flat[i])\n",
        "\n",
        "\n",
        "\n",
        "    # Compute span accuracy\n",
        "    span_accuracy = int(np.array_equal(pred_labels_str, true_labels_str))\n",
        "\n",
        "    # Compute precision and recall\n",
        "    precision, recall, _, _ = precision_recall_fscore_support(true_labels_str, pred_labels_str, average='micro')\n",
        "\n",
        "    # Create a dictionary of metrics\n",
        "    metrics = {\n",
        "        TOKEN_ACCURACY: token_accuracy,\n",
        "        SPAN_ACCURACY: span_accuracy,\n",
        "        MEAN_TOKEN_PRECISION: precision,\n",
        "        MEAN_TOKEN_RECALL: recall,\n",
        "        MEAN_SPAN_PRECISION: precision,\n",
        "        MEAN_SPAN_RECALL: recall,\n",
        "    }\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HiK65MW8TXOP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHYkLDbROtrk",
        "outputId": "3c83245c-3b15-44d4-cdb2-3453431c35da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: [CLS], Label: O\n",
            "Word: the, Label: O\n",
            "Word: catechol, Label: B-Chemical\n",
            "Word: and, Label: O\n",
            "Word: hydroquinone, Label: B-Chemical\n",
            "Word: metabolites, Label: O\n",
            "Word: ,, Label: O\n",
            "Word: ncq436, Label: O\n",
            "Word: and, Label: O\n",
            "Word: ncq344, Label: O\n",
            "Word: ,, Label: O\n",
            "Word: induced, Label: O\n",
            "Word: apoptosis, Label: O\n",
            "Word: in, Label: O\n",
            "Word: hl60, Label: O\n",
            "Word: and, Label: O\n",
            "Word: hbmp, Label: O\n",
            "Word: cells, Label: O\n",
            "Word: in, Label: O\n",
            "Word: a, Label: O\n",
            "Word: time, Label: O\n",
            "Word: -, Label: O\n",
            "Word: and, Label: O\n",
            "Word: concentration, Label: O\n",
            "Word: dependent, Label: O\n",
            "Word: manner, Label: O\n",
            "Word: ,, Label: O\n",
            "Word: while, Label: O\n",
            "Word: the, Label: O\n",
            "Word: phenols, Label: O\n",
            "Word: ,, Label: O\n",
            "Word: ncr181, Label: O\n",
            "Word: ,, Label: O\n",
            "Word: fla873, Label: O\n",
            "Word: ,, Label: O\n",
            "Word: and, Label: O\n",
            "Word: fla797, Label: O\n",
            "Word: ,, Label: O\n",
            "Word: and, Label: O\n",
            "Word: the, Label: O\n",
            "Word: derivatives, Label: O\n",
            "Word: formed, Label: O\n",
            "Word: by, Label: O\n",
            "Word: oxidation, Label: O\n",
            "Word: of, Label: O\n",
            "Word: the, Label: O\n",
            "Word: pyrrolidine, Label: B-Chemical\n",
            "Word: ring, Label: O\n",
            "Word: ,, Label: O\n",
            "Word: fla838, Label: O\n",
            "Word: ,, Label: O\n",
            "Word: ncm001, Label: O\n",
            "Word: ,, Label: O\n",
            "Word: and, Label: O\n",
            "Word: ncl118, Label: O\n",
            "Word: ,, Label: O\n",
            "Word: had, Label: O\n",
            "Word: no, Label: O\n",
            "Word: effect, Label: O\n",
            "Word: ., Label: O\n",
            "Word: [SEP], Label: O\n"
          ]
        }
      ],
      "source": [
        "text = \" \".join(test_examples[56].words)\n",
        "\n",
        "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n",
        "\n",
        "input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "attention_mask = [1] * len(input_ids)\n",
        "token_type_ids = [0] * len(input_ids)\n",
        "\n",
        "input_ids = torch.tensor(input_ids).unsqueeze(0).to('cpu')  # Move input tensors to the CPU\n",
        "attention_mask = torch.tensor(attention_mask).unsqueeze(0).to('cpu')\n",
        "token_type_ids = torch.tensor(token_type_ids).unsqueeze(0).to('cpu')\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits = model1(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids).logits\n",
        "\n",
        "predicted_label_ids = torch.argmax(logits, dim=2).squeeze().tolist()\n",
        "\n",
        "\n",
        "tagged_words = []\n",
        "current_word = \"\"\n",
        "current_label = \"\"\n",
        "\n",
        "# Loop through tokens, subwords, and their corresponding predicted labels\n",
        "for token, predicted_label_id in zip(tokens, predicted_label_ids):\n",
        "    label = list(label_map.keys())[list(label_map.values()).index(predicted_label_id)]\n",
        "\n",
        "    if token.startswith(\"##\"):\n",
        "        current_word += token[2:]\n",
        "    else:\n",
        "        # If we have an existing entity, add it to the tagged_words list\n",
        "        if current_word:\n",
        "            tagged_words.append((current_word, current_label))\n",
        "        current_word = token\n",
        "        current_label = label\n",
        "\n",
        "# Add the last entity if any\n",
        "if current_word:\n",
        "    tagged_words.append((current_word, current_label))\n",
        "\n",
        "# Print the tagged words and their labels\n",
        "for word, label in tagged_words:\n",
        "    print(f\"Word: {word}, Label: {label}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzYyzbvNVZug"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
